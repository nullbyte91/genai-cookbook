{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Manually set root if in notebook\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from datasets.loader import get_data_loaders\n",
    "from datasets.instruction import format_input\n",
    "\n",
    "from inference.generate import text_to_token_ids, token_ids_to_text\n",
    "\n",
    "from models.gpt2.gpt_model_v1 import GPTModel\n",
    "from models.gpt2.config import BASE_CONFIG, model_configs, CHOOSE_MODEL\n",
    "from scripts.gpt2.train import train_model_simple\n",
    "from utils.loader import download_and_load_file\n",
    "from utils.gpt2_utils import *\n",
    "from utils.gpt2_utils import download_and_load_gpt2\n",
    "\n",
    "from inference.generate import generate_and_print_sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = \"instruction-data.json\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    "data = download_and_load_file(file_path, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/355M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 1024)\n",
       "  (pos_emb): Embedding(1024, 1024)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (12): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (13): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (14): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (15): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (16): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (17): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (18): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (19): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (20): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (21): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (22): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (23): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (W_value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].strip(\"()\")\n",
    "settings, params = download_and_load_gpt2(model_size, models_dir=\"gpt2\")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "\n",
    "# Load to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loaders\n",
    "train_loader, val_loader, _ = get_data_loaders(train_data, val_data, test_data, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.311, Val loss 0.650\n",
      "Ep 1 (Step 000005): Train loss 0.301, Val loss 0.666\n",
      "Ep 1 (Step 000010): Train loss 0.316, Val loss 0.702\n",
      "Ep 1 (Step 000015): Train loss 0.286, Val loss 0.714\n",
      "Ep 1 (Step 000020): Train loss 0.316, Val loss 0.723\n",
      "Ep 1 (Step 000025): Train loss 0.282, Val loss 0.719\n",
      "Ep 1 (Step 000030): Train loss 0.305, Val loss 0.708\n",
      "Ep 1 (Step 000035): Train loss 0.272, Val loss 0.699\n",
      "Ep 1 (Step 000040): Train loss 0.265, Val loss 0.704\n",
      "Ep 1 (Step 000045): Train loss 0.266, Val loss 0.710\n",
      "Ep 1 (Step 000050): Train loss 0.270, Val loss 0.694\n",
      "Ep 1 (Step 000055): Train loss 0.251, Val loss 0.690\n",
      "Ep 1 (Step 000060): Train loss 0.260, Val loss 0.692\n",
      "Ep 1 (Step 000065): Train loss 0.253, Val loss 0.687\n",
      "Ep 1 (Step 000070): Train loss 0.238, Val loss 0.683\n",
      "Ep 1 (Step 000075): Train loss 0.261, Val loss 0.678\n",
      "Ep 1 (Step 000080): Train loss 0.256, Val loss 0.681\n",
      "Ep 1 (Step 000085): Train loss 0.274, Val loss 0.670\n",
      "Ep 1 (Step 000090): Train loss 0.250, Val loss 0.669\n",
      "Ep 1 (Step 000095): Train loss 0.234, Val loss 0.669\n",
      "Ep 1 (Step 000100): Train loss 0.237, Val loss 0.675\n",
      "Ep 1 (Step 000105): Train loss 0.238, Val loss 0.668\n",
      "Ep 1 (Step 000110): Train loss 0.222, Val loss 0.671\n",
      "Ep 1 (Step 000115): Train loss 0.247, Val loss 0.676\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637]], device='cuda:0')\n",
      "tensor([[198]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198]], device='cuda:0')\n",
      "tensor([[198]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198]], device='cuda:0')\n",
      "tensor([[21017]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017]], device='cuda:0')\n",
      "tensor([[18261]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261]], device='cuda:0')\n",
      "tensor([[25]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25]], device='cuda:0')\n",
      "tensor([[198]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198]], device='cuda:0')\n",
      "tensor([[464]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464]],\n",
      "       device='cuda:0')\n",
      "tensor([[9799]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799]],\n",
      "       device='cuda:0')\n",
      "tensor([[318]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318]],\n",
      "       device='cuda:0')\n",
      "tensor([[15847]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847]], device='cuda:0')\n",
      "tensor([[790]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790]], device='cuda:0')\n",
      "tensor([[1110]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110]], device='cuda:0')\n",
      "tensor([[416]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416]], device='cuda:0')\n",
      "tensor([[262]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262]], device='cuda:0')\n",
      "tensor([[21221]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221]], device='cuda:0')\n",
      "tensor([[13]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13]], device='cuda:0')\n",
      "tensor([[50256]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256]],\n",
      "       device='cuda:0')\n",
      "tensor([[464]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464]],\n",
      "       device='cuda:0')\n",
      "tensor([[1708]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708]],\n",
      "       device='cuda:0')\n",
      "tensor([[318]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318]], device='cuda:0')\n",
      "tensor([[281]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281]], device='cuda:0')\n",
      "tensor([[12064]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064]], device='cuda:0')\n",
      "tensor([[326]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326]], device='cuda:0')\n",
      "tensor([[8477]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477]], device='cuda:0')\n",
      "tensor([[257]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257]], device='cuda:0')\n",
      "tensor([[4876]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876]], device='cuda:0')\n",
      "tensor([[13]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13]],\n",
      "       device='cuda:0')\n",
      "tensor([[19430]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430]],\n",
      "       device='cuda:0')\n",
      "tensor([[257]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257]],\n",
      "       device='cuda:0')\n",
      "tensor([[2882]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882]], device='cuda:0')\n",
      "tensor([[326]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326]], device='cuda:0')\n",
      "tensor([[20431]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431]], device='cuda:0')\n",
      "tensor([[32543]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543]], device='cuda:0')\n",
      "tensor([[262]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262]], device='cuda:0')\n",
      "tensor([[2581]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581]], device='cuda:0')\n",
      "tensor([[13]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13]], device='cuda:0')\n",
      "tensor([[198]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198]],\n",
      "       device='cuda:0')\n",
      "tensor([[198]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198]],\n",
      "       device='cuda:0')\n",
      "tensor([[21017]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017]],\n",
      "       device='cuda:0')\n",
      "tensor([[46486]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486]], device='cuda:0')\n",
      "tensor([[25]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25]], device='cuda:0')\n",
      "tensor([[198]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25,   198]], device='cuda:0')\n",
      "tensor([[2061]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25,   198,  2061]], device='cuda:0')\n",
      "tensor([[318]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25,   198,  2061,   318]], device='cuda:0')\n",
      "tensor([[262]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25,   198,  2061,   318,   262]], device='cuda:0')\n",
      "tensor([[3139]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25,   198,  2061,   318,   262,  3139]], device='cuda:0')\n",
      "tensor([[286]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25,   198,  2061,   318,   262,  3139,   286]],\n",
      "       device='cuda:0')\n",
      "tensor([[262]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25,   198,  2061,   318,   262,  3139,   286,   262]],\n",
      "       device='cuda:0')\n",
      "tensor([[1578]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25,   198,  2061,   318,   262,  3139,   286,   262,  1578]],\n",
      "       device='cuda:0')\n",
      "tensor([[1829]], device='cuda:0')\n",
      "\n",
      "--- SAMPLE OUTPUT ---\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United States\n",
      "Ep 2 (Step 000120): Train loss 0.249, Val loss 0.695\n",
      "Ep 2 (Step 000125): Train loss 0.224, Val loss 0.714\n",
      "Ep 2 (Step 000130): Train loss 0.249, Val loss 0.733\n",
      "Ep 2 (Step 000135): Train loss 0.238, Val loss 0.731\n",
      "Ep 2 (Step 000140): Train loss 0.236, Val loss 0.712\n",
      "Ep 2 (Step 000145): Train loss 0.216, Val loss 0.710\n",
      "Ep 2 (Step 000150): Train loss 0.200, Val loss 0.714\n",
      "Ep 2 (Step 000155): Train loss 0.228, Val loss 0.715\n",
      "Ep 2 (Step 000160): Train loss 0.202, Val loss 0.698\n",
      "Ep 2 (Step 000165): Train loss 0.228, Val loss 0.697\n",
      "Ep 2 (Step 000170): Train loss 0.223, Val loss 0.705\n",
      "Ep 2 (Step 000175): Train loss 0.212, Val loss 0.723\n",
      "Ep 2 (Step 000180): Train loss 0.223, Val loss 0.723\n",
      "Ep 2 (Step 000185): Train loss 0.200, Val loss 0.697\n",
      "Ep 2 (Step 000190): Train loss 0.217, Val loss 0.683\n",
      "Ep 2 (Step 000195): Train loss 0.217, Val loss 0.678\n",
      "Ep 2 (Step 000200): Train loss 0.194, Val loss 0.678\n",
      "Ep 2 (Step 000205): Train loss 0.198, Val loss 0.699\n",
      "Ep 2 (Step 000210): Train loss 0.204, Val loss 0.711\n",
      "Ep 2 (Step 000215): Train loss 0.201, Val loss 0.698\n",
      "Ep 2 (Step 000220): Train loss 0.203, Val loss 0.692\n",
      "Ep 2 (Step 000225): Train loss 0.196, Val loss 0.696\n",
      "Ep 2 (Step 000230): Train loss 0.211, Val loss 0.707\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637]], device='cuda:0')\n",
      "tensor([[198]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198]], device='cuda:0')\n",
      "tensor([[198]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198]], device='cuda:0')\n",
      "tensor([[21017]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017]], device='cuda:0')\n",
      "tensor([[18261]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261]], device='cuda:0')\n",
      "tensor([[25]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25]], device='cuda:0')\n",
      "tensor([[198]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198]], device='cuda:0')\n",
      "tensor([[464]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464]],\n",
      "       device='cuda:0')\n",
      "tensor([[9799]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799]],\n",
      "       device='cuda:0')\n",
      "tensor([[318]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318]],\n",
      "       device='cuda:0')\n",
      "tensor([[15847]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847]], device='cuda:0')\n",
      "tensor([[790]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790]], device='cuda:0')\n",
      "tensor([[1110]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110]], device='cuda:0')\n",
      "tensor([[416]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416]], device='cuda:0')\n",
      "tensor([[262]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262]], device='cuda:0')\n",
      "tensor([[21221]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221]], device='cuda:0')\n",
      "tensor([[13]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13]], device='cuda:0')\n",
      "tensor([[50256]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256]],\n",
      "       device='cuda:0')\n",
      "tensor([[464]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464]],\n",
      "       device='cuda:0')\n",
      "tensor([[1708]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708]],\n",
      "       device='cuda:0')\n",
      "tensor([[318]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318]], device='cuda:0')\n",
      "tensor([[281]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281]], device='cuda:0')\n",
      "tensor([[12064]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064]], device='cuda:0')\n",
      "tensor([[326]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326]], device='cuda:0')\n",
      "tensor([[8477]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477]], device='cuda:0')\n",
      "tensor([[257]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257]], device='cuda:0')\n",
      "tensor([[4876]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876]], device='cuda:0')\n",
      "tensor([[13]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13]],\n",
      "       device='cuda:0')\n",
      "tensor([[19430]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430]],\n",
      "       device='cuda:0')\n",
      "tensor([[257]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257]],\n",
      "       device='cuda:0')\n",
      "tensor([[2882]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882]], device='cuda:0')\n",
      "tensor([[326]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326]], device='cuda:0')\n",
      "tensor([[20431]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431]], device='cuda:0')\n",
      "tensor([[32543]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543]], device='cuda:0')\n",
      "tensor([[262]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262]], device='cuda:0')\n",
      "tensor([[2581]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581]], device='cuda:0')\n",
      "tensor([[13]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13]], device='cuda:0')\n",
      "tensor([[198]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198]],\n",
      "       device='cuda:0')\n",
      "tensor([[198]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198]],\n",
      "       device='cuda:0')\n",
      "tensor([[21017]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017]],\n",
      "       device='cuda:0')\n",
      "tensor([[46486]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486]], device='cuda:0')\n",
      "tensor([[25]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25]], device='cuda:0')\n",
      "tensor([[198]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25,   198]], device='cuda:0')\n",
      "tensor([[2061]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25,   198,  2061]], device='cuda:0')\n",
      "tensor([[318]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25,   198,  2061,   318]], device='cuda:0')\n",
      "tensor([[262]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25,   198,  2061,   318,   262]], device='cuda:0')\n",
      "tensor([[3139]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25,   198,  2061,   318,   262,  3139]], device='cuda:0')\n",
      "tensor([[286]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25,   198,  2061,   318,   262,  3139,   286]],\n",
      "       device='cuda:0')\n",
      "tensor([[262]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25,   198,  2061,   318,   262,  3139,   286,   262]],\n",
      "       device='cuda:0')\n",
      "tensor([[13316]], device='cuda:0')\n",
      "tensor([[21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "           257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "         21017, 46486,    25,   198,  3103,  1851,   262,  4075,  6827,   284,\n",
      "         14513,    25,   705,   464, 21221, 38383,   262,  9799,   790,  1110,\n",
      "          2637,   198,   198, 21017, 18261,    25,   198,   464,  9799,   318,\n",
      "         15847,   790,  1110,   416,   262, 21221,    13, 50256,   464,  1708,\n",
      "           318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
      "          2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
      "         46486,    25,   198,  2061,   318,   262,  3139,   286,   262, 13316]],\n",
      "       device='cuda:0')\n",
      "tensor([[30]], device='cuda:0')\n",
      "\n",
      "--- SAMPLE OUTPUT ---\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the Philippines?\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, tokens_seen  = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=2, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]),\n",
    "    tokenizer=tokenizer,\n",
    "    sample_fn=generate_and_print_sample\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAg/FJREFUeJzt3Xd4FMXjBvD3LuXSC+khjRIIgUAgkBiKoARCkY4UkSaCIgiIIPJTaX4VVERUEGwQC1IFROmEIiUQWiAQCJ0ESKGl97v5/bHk4CQJKZdccnk/z3NPcruze7N7Ke/N7szIhBACRERERFTjyXVdASIiIiLSDgY7IiIiIj3BYEdERESkJxjsiIiIiPQEgx0RERGRnmCwIyIiItITDHZEREREeoLBjoiIiEhPMNgRERER6QkGOyLSezdu3IBMJkNUVJSuq0JEVKkY7IioRpDJZCU+5syZo+sqEhHpnKGuK0BEVBoJCQnq79euXYtZs2YhNjZWvczCwkIX1SIiqlbYYkdENYKzs7P6YW1tDZlMpn7u6OiIRYsWwc3NDQqFAv7+/tixY0ex+1IqlXjttdfg4+ODuLg4AMBff/2FVq1awcTEBPXr18fcuXNRUFCg3kYmk+Gnn35Cv379YGZmBm9vb2zZskW9/uHDhxg2bBgcHBxgamoKb29vrFy5stg6bNiwAX5+fjA1NYWdnR1CQkKQmZmpXv/TTz+hSZMmMDExgY+PD7777juN7ePj4zFo0CDY2NigTp066NOnD27cuKFeP2rUKPTt2xcLFy6Ei4sL7OzsMGHCBOTn55f6nBNRzcNgR0Q13tdff40vv/wSCxcuxNmzZxEaGorevXvj8uXLT5XNzc3Fyy+/jKioKBw8eBAeHh44ePAgRowYgcmTJyMmJgbff/89wsLC8Mknn2hsO3fuXAwaNAhnz55Fjx49MGzYMDx48AAA8NFHHyEmJgbbt2/HhQsXsGzZMtjb2xdZ34SEBAwdOhSvvfYaLly4gP3796N///4QQgAAVq1ahVmzZuGTTz7BhQsX8Omnn+Kjjz7CL7/8AgDIz89HaGgoLC0tcfDgQRw+fBgWFhbo1q0b8vLy1K+zb98+XL16Ffv27cMvv/yCsLAwhIWFaeOUE1F1JYiIapiVK1cKa2tr9XNXV1fxySefaJRp06aNeOutt4QQQly/fl0AEAcPHhSdO3cW7du3FykpKeqynTt3Fp9++qnG9r/99ptwcXFRPwcgPvzwQ/XzjIwMAUBs375dCCFEr169xOjRo0tV/5MnTwoA4saNG0Wub9Cggfjjjz80ln388cciODhYXbfGjRsLlUqlXp+bmytMTU3Fzp07hRBCjBw5Unh6eoqCggJ1mZdfflkMHjy4VHUkopqJ99gRUY2WlpaGO3fuoF27dhrL27VrhzNnzmgsGzp0KNzc3LB3716Ympqql585cwaHDx/WaKFTKpXIyclBVlYWzMzMAADNmzdXrzc3N4eVlRWSk5MBAOPHj8eAAQNw6tQpdO3aFX379kXbtm2LrHOLFi3QuXNn+Pn5ITQ0FF27dsXAgQNha2uLzMxMXL16FWPGjMHYsWPV2xQUFMDa2lpd3ytXrsDS0lJjvzk5Obh69ar6edOmTWFgYKB+7uLigujo6BLOJhHVdAx2RFRr9OjRA7///jsiIiLw4osvqpdnZGRg7ty56N+//1PbmJiYqL83MjLSWCeTyaBSqQAA3bt3x82bN7Ft2zbs3r0bnTt3xoQJE7Bw4cKn9mlgYIDdu3fjyJEj2LVrF7799lt88MEHOHbsmDpE/vjjjwgKCnpqu8L6BgQEYNWqVU/t28HBoVT1JSL9xGBHRDWalZUVXF1dcfjwYXTs2FG9/PDhwwgMDNQoO378eDRr1gy9e/fG1q1b1eVbtWqF2NhYNGzYsEJ1cXBwwMiRIzFy5Eh06NAB06dPLzLYAVLIateuHdq1a4dZs2bB09MTmzZtwtSpU+Hq6opr165h2LBhRW7bqlUrrF27Fo6OjrCysqpQnYlIvzDYEVGNN336dMyePRsNGjSAv78/Vq5ciaioqCJbtN5++20olUq89NJL2L59O9q3b49Zs2bhpZdegoeHBwYOHAi5XI4zZ87g3Llz+N///leqOsyaNQsBAQFo2rQpcnNz8c8//6BJkyZFlj127BjCw8PRtWtXODo64tixY7h79666/Ny5czFp0iRYW1ujW7duyM3NxYkTJ/Dw4UNMnToVw4YNwxdffIE+ffpg3rx5cHNzw82bN7Fx40a89957cHNzK//JJKIajcGOiGq8SZMmITU1Fe+++y6Sk5Ph6+uLLVu2wNvbu8jyU6ZMgUqlQo8ePbBjxw6Ehobin3/+wbx58/DZZ5/ByMgIPj4+eP3110tdB2NjY8ycORM3btyAqakpOnTogDVr1hRZ1srKCv/++y8WL16MtLQ0eHp64ssvv0T37t0BAK+//jrMzMzwxRdfYPr06TA3N4efnx+mTJkCADAzM8O///6LGTNmoH///khPT0fdunXRuXNntuAR1XIyIR71ryciIiKiGo3j2BERERHpCQY7IiIiIj3BYEdERESkJxjsiIiIiPQEgx0RERGRnmCwIyIiItITDHZatHTpUnh5ecHExARBQUGIjIzUdZUq1fz589GmTRtYWlrC0dERffv2RWxsrEaZnJwcTJgwAXZ2drCwsMCAAQOQlJSkUSYuLg49e/aEmZkZHB0dMX36dBQUFGiU2b9/P1q1agWFQoGGDRsiLCzsqfrU5PO/YMECyGQy9ThlAM9dSW7fvo1XX30VdnZ2MDU1hZ+fH06cOKFeL4TArFmz4OLiAlNTU4SEhODy5csa+3jw4AGGDRsGKysr2NjYYMyYMcjIyNAoc/bsWXTo0AEmJiZwd3fH559//lRd1q9fDx8fH5iYmMDPzw/btm2rnIPWAqVSiY8++gj16tWDqakpGjRogI8//hhPjnrFc/fYv//+i169esHV1RUymQybN2/WWF+dzlVp6lKVSjp3+fn5mDFjBvz8/GBubg5XV1eMGDECd+7c0dhHbT13FSZIK9asWSOMjY3FihUrxPnz58XYsWOFjY2NSEpK0nXVKk1oaKhYuXKlOHfunIiKihI9evQQHh4eIiMjQ13mzTffFO7u7iI8PFycOHFCPPfcc6Jt27bq9QUFBaJZs2YiJCREnD59Wmzbtk3Y29uLmTNnqstcu3ZNmJmZialTp4qYmBjx7bffCgMDA7Fjxw51mZp8/iMjI4WXl5do3ry5mDx5sno5z13RHjx4IDw9PcWoUaPEsWPHxLVr18TOnTvFlStX1GUWLFggrK2txebNm8WZM2dE7969Rb169UR2dra6TLdu3USLFi3E0aNHxcGDB0XDhg3F0KFD1etTU1OFk5OTGDZsmDh37pxYvXq1MDU1Fd9//726zOHDh4WBgYH4/PPPRUxMjPjwww+FkZGRiI6OrpqTUUaffPKJsLOzE//884+4fv26WL9+vbCwsBBff/21ugzP3WPbtm0TH3zwgdi4caMAIDZt2qSxvjqdq9LUpSqVdO5SUlJESEiIWLt2rbh48aKIiIgQgYGBIiAgQGMftfXcVRSDnZYEBgaKCRMmqJ8rlUrh6uoq5s+fr8NaVa3k5GQBQBw4cEAIIf3yGhkZifXr16vLXLhwQQAQERERQgjpl18ul4vExER1mWXLlgkrKyuRm5srhBDivffeE02bNtV4rcGDB4vQ0FD185p6/tPT04W3t7fYvXu36NixozrY8dwVb8aMGaJ9+/bFrlepVMLZ2Vl88cUX6mUpKSlCoVCI1atXCyGEiImJEQDE8ePH1WW2b98uZDKZuH37thBCiO+++07Y2tqqz2Xhazdu3Fj9fNCgQaJnz54arx8UFCTeeOONih1kJenZs6d47bXXNJb1799fDBs2TAjBc1eS/4aT6nSuSlMXXSoqFP9XZGSkACBu3rwphOC5qwheitWCvLw8nDx5EiEhIeplcrkcISEhiIiI0GHNqlZqaioAoE6dOgCAkydPIj8/X+O8+Pj4wMPDQ31eIiIi4OfnBycnJ3WZ0NBQpKWl4fz58+oyT+6jsEzhPmry+Z8wYQJ69uz51PHx3BVvy5YtaN26NV5++WU4OjqiZcuW+PHHH9Xrr1+/jsTERI1jsra2RlBQkMa5s7GxQevWrdVlQkJCIJfLcezYMXWZ559/HsbGxuoyoaGhiI2NxcOHD9VlSjq/1U3btm0RHh6OS5cuAQDOnDmDQ4cOqacy47krvep0rkpTl+ouNTUVMpkMNjY2AHjuKoLBTgvu3bsHpVKp8Q8WAJycnJCYmKijWlUtlUqFKVOmoF27dmjWrBkAIDExEcbGxupf1EJPnpfExMQiz1vhupLKpKWlITs7u8ae/zVr1uDUqVOYP3/+U+t47op37do1LFu2DN7e3ti5cyfGjx+PSZMm4ZdffgHw+NhLOqbExEQ4OjpqrDc0NESdOnW0cn6r67l7//33MWTIEPj4+MDIyAgtW7bElClTMGzYMAA8d2VRnc5VaepSneXk5GDGjBkYOnSoeq5jnrvyM9R1BUg/TJgwAefOncOhQ4d0XZUaIT4+HpMnT8bu3bthYmKi6+rUKCqVCq1bt8ann34KAGjZsiXOnTuH5cuXY+TIkTquXfW2bt06rFq1Cn/88QeaNm2KqKgoTJkyBa6urjx3pBP5+fkYNGgQhBBYtmyZrqujF9hipwX29vYwMDB4qsdiUlISnJ2ddVSrqjNx4kT8888/2LdvH9zc3NTLnZ2dkZeXh5SUFI3yT54XZ2fnIs9b4bqSylhZWcHU1LRGnv+TJ08iOTkZrVq1gqGhIQwNDXHgwAF88803MDQ0hJOTE89dMVxcXODr66uxrEmTJoiLiwPw+NhLOiZnZ2ckJydrrC8oKMCDBw+0cn6r67mbPn26utXOz88Pw4cPxzvvvKNuNea5K73qdK5KU5fqqDDU3bx5E7t371a31gE8dxXBYKcFxsbGCAgIQHh4uHqZSqVCeHg4goODdVizyiWEwMSJE7Fp0ybs3bsX9erV01gfEBAAIyMjjfMSGxuLuLg49XkJDg5GdHS0xi9w4S944T/v4OBgjX0UlincR008/507d0Z0dDSioqLUj9atW2PYsGHq73nuitauXbunhtW5dOkSPD09AQD16tWDs7OzxjGlpaXh2LFjGucuJSUFJ0+eVJfZu3cvVCoVgoKC1GX+/fdf5Ofnq8vs3r0bjRs3hq2trbpMSee3usnKyoJcrvln38DAACqVCgDPXVlUp3NVmrpUN4Wh7vLly9izZw/s7Ow01vPcVYCue2/oizVr1giFQiHCwsJETEyMGDdunLCxsdHosahvxo8fL6ytrcX+/ftFQkKC+pGVlaUu8+abbwoPDw+xd+9eceLECREcHCyCg4PV6wuH7OjatauIiooSO3bsEA4ODkUO2TF9+nRx4cIFsXTp0iKH7Kjp5//JXrFC8NwVJzIyUhgaGopPPvlEXL58WaxatUqYmZmJ33//XV1mwYIFwsbGRvz111/i7Nmzok+fPkUOQ9GyZUtx7NgxcejQIeHt7a0xlEJKSopwcnISw4cPF+fOnRNr1qwRZmZmTw2lYGhoKBYuXCguXLggZs+eXe2G7HjSyJEjRd26ddXDnWzcuFHY29uL9957T12G5+6x9PR0cfr0aXH69GkBQCxatEicPn1a3XOzOp2r0tSlKpV07vLy8kTv3r2Fm5ubiIqK0vj/8WQP19p67iqKwU6Lvv32W+Hh4SGMjY1FYGCgOHr0qK6rVKkAFPlYuXKlukx2drZ46623hK2trTAzMxP9+vUTCQkJGvu5ceOG6N69uzA1NRX29vbi3XffFfn5+Rpl9u3bJ/z9/YWxsbGoX7++xmsUqunn/7/BjueueH///bdo1qyZUCgUwsfHR/zwww8a61Uqlfjoo4+Ek5OTUCgUonPnziI2NlajzP3798XQoUOFhYWFsLKyEqNHjxbp6ekaZc6cOSPat28vFAqFqFu3rliwYMFTdVm3bp1o1KiRMDY2Fk2bNhVbt27V/gFrSVpampg8ebLw8PAQJiYmon79+uKDDz7Q+GfKc/fYvn37ivwbN3LkSCFE9TpXpalLVSrp3F2/fr3Y/x/79u1T76O2nruKkgnxxJDjRERERFRj8R47IiIiIj3BYEdERESkJxjsiIiIiPQEgx0RERGRnmCwIyIiItITDHZEREREeoLBTotyc3MxZ84c5Obm6roqNRLPX/nx3JUfz1358dyVH89dxfD8FY/j2GlRWloarK2tkZqaqjHnHZUOz1/58dyVH89d+fHclR/PXcXw/BWPLXZEREREeoLBjoiIiEhPGOq6AlWtoKAAp0+fhpOTE+Ry7eba9PR0AMDt27eRlpam1X3XBjx/5cdzV348d+XHc1d+PHcVU9vOn0qlQlJSElq2bAlDw5KjW627x+748eMIDAzUdTWIiIiIyiQyMhJt2rQpsUyta7FzcnICIJ0cFxcXHdeGiIiIqGQJCQkIDAxUZ5iS1LpgV3j51cXFBW5ubjquDREREVHplOYWMnaeICIiItITDHZEREREeoLBjoiIiEhP1Lp77IiIiLRFqVQiPz9f19WgGs7IyAgGBgZa2ReDHRERURkJIZCYmIiUlBRdV4X0hI2NDZydnSGTySq0HwY7IiKiMioMdY6OjjAzM6vwP2OqvYQQyMrKQnJyMgBUeCg2BjsiIqIyUCqV6lBnZ2en6+qQHjA1NQUAJCcnw9HRsUKXZdl5goiIqAwK76kzMzPTcU1InxT+PFX0nk0GOyIionLg5VfSJm39PDHYEREREekJBjsiIiIqNy8vLyxevLjU5ffv3w+ZTFbpPYrDwsJgY2NTqa9RHTHYERER1QIymazEx5w5c8q13+PHj2PcuHGlLt+2bVskJCTA2tq6XK9HJWOvWCIifVKQCwgVYGSq65pQNZOQkKD+fu3atZg1axZiY2PVyywsLNTfCyGgVCphaPjsmODg4FCmehgbG8PZ2blM21DpscWOiEhfXN4DLPQGPnEGPqsHLG8P/DEE2DoNOPQVEPOXrmtIOuTs7Kx+WFtbQyaTqZ9fvHgRlpaW2L59OwICAqBQKHDo0CFcvXoVffr0gZOTEywsLNCmTRvs2bNHY7//vRQrk8nw008/oV+/fjAzM4O3tze2bNmiXv/fS7GFl0x37tyJJk2awMLCAt26ddMIogUFBZg0aRJsbGxgZ2eHGTNmYOTIkejbt2+ZzsGyZcvQoEEDGBsbo3Hjxvjtt9/U64QQmDNnDjw8PKBQKODq6opJkyap13/33Xfw9vaGiYkJnJycMHDgwDK9dlVhsCMi0gc3jwBrXwVyUqXn2Q+AxGjg0nbg+I/AnjnAvk81t/m1L7D3f4AQVV1bvSOEQFZegU4eQovv3/vvv48FCxbgwoULaN68OTIyMtCjRw+Eh4fj9OnT6NatG3r16oW4uLgS9zN37lwMGjQIZ8+eRY8ePTBs2DA8ePCg2PJZWVlYuHAhfvvtN/z777+Ii4vDtGnT1Os/++wzrFq1CitXrsThw4eRlpaGzZs3l+nYNm3ahMmTJ+Pdd9/FuXPn8MYbb2D06NHYt28fAODPP//EV199he+//x6XL1/G5s2b4efnBwA4ceIEJk2ahHnz5iE2NhY7duzA888/X6bXryq8FEtEVNPdOQ2sGgQUZAPeoUDf74D0RCDtNpB669HX24Cl03+2OwVc2wd4tgUavKibuuuJ7HwlfGft1Mlrx8wLhZmxdv6dz5s3D126dFE/r1OnDlq0aKF+/vHHH2PTpk3YsmULJk6cWOx+Ro0ahaFDhwIAPv30U3zzzTeIjIxEt27diiyfn5+P5cuXo0GDBgCAiRMnYt68eer13377LWbOnIl+/foBAJYsWYJt27aV6dgWLlyIUaNG4a233gIATJ06FUePHsXChQvxwgsvIC4uDs7OzggJCYGRkRE8PDwQGBgIAIiLi4O5uTleeuklWFpawtPTEy1btizT61cVBjsioprsbizw+wAgLx3wbA8M+kW6v87cHnBuVvK2HR61iDDU0SOtW7fWeJ6RkYE5c+Zg69atSEhIQEFBAbKzs5/ZYte8eXP19+bm5rCyslJPmVUUMzMzdagDpGm1CsunpqYiKSlJHbIAwMDAAAEBAVCpVKU+tgsXLjzVyaNdu3b4+uuvAQAvv/wyFi9ejPr166Nbt27o0aMHevXqBUNDQ3Tp0gWenp7qdd26dVNfaq5uGOyIiGqqzPvS5dSs+4BrS2Do6rJ1mmg3SfN5QS5gYAxw4N0yMzUyQMy8UJ29traYm5trPJ82bRp2796NhQsXomHDhjA1NcXAgQORl5dX4n6MjIw0nstkshJDWFHltXmJuTTc3d0RGxuLPXv2YPfu3XjrrbfwxRdf4MCBA7C0tMSpU6ewf/9+7Nq1C7NmzcKcOXNw/PjxajekCu+xIyKqqczqAK2GAw4+wKsbAROr8u8rJxUIewnYv0B79atFZDIZzIwNNR9yJczyU2BWkAYzZQbMDPB4naEMZgYCZobyp7cr46MyZ8A4fPgwRo0ahX79+sHPzw/Ozs64ceNGpb1eUaytreHk5ITjx4+rlymVSpw6dapM+2nSpAkOHz6ssezw4cPw9fVVPzc1NUWvXr3wzTffYP/+/YiIiEB0dDQAwNDQECEhIfj8889x9uxZ3LhxA3v37q3AkVUOttjRY5d3A7s+AlxaPHo0B5z9ABOONURULclkwAv/B7SbDBibP7t8SS7tAm5FSg8DQ+D56dqpY22VmwE8uCoNPVPIvpF0bgEg6x6QdgcwtQVsvXRSxdLw9vbGxo0b0atXL8hkMnz00UdluvypLW+//Tbmz5+Phg0bwsfHB99++y0ePnxYplA7ffp0DBo0CC1btkRISAj+/vtvbNy4Ud3LNywsDEqlEkFBQTAzM8Pvv/8OU1NTeHp64p9//sG1a9fw/PPPw9bWFtu2bYNKpULjxo0r65DLjcGutspJAyKWAvU7SjdOA8DtU8DdC9Lj7JrHZevUB5ybPxH4Wkj37xBR1ctNl1rVXvi/x2GuoqEOAJq/LHWy2DNb6ilrYCwFRiq7J0OdoQkgN5S+lz9xybTwMqPsiWV5mUD2Q8CqbrW5HL5o0SK89tpraNu2Lezt7TFjxgykpaVVeT1mzJiBxMREjBgxAgYGBhg3bhxCQ0NhYFD6y9B9+/bF119/jYULF2Ly5MmoV68eVq5ciU6dOgEAbGxssGDBAkydOhVKpRJ+fn74+++/YWdnBxsbG2zcuBFz5sxBTk4OvL29sXr1ajRt2rSSjrj8ZKKqL2Lr2K1bt+Du7o74+Hi4ubnpujq6s/MDIGIJ4BYIjNkl/RHJSAZunwQSzgIJZ4DEs0BqfNHbuz8H9PhCatUjoqrzxxBpCJPGPYGhf2h///9+IQU7AAidDwS/pf3XqOFycnJw/fp11KtXDyYmJpor8zKB+1ekIGdsKX0wlhdz15MQAAQgkwOqAiDpvLSdtTs/PD+DSqVCkyZNMGjQIHz88ce6ro5WlPRzVZbswha72kJZAOSkPP5j0fZt4MZBIHjC4zIWjkDj7tKjUOZ9KeAlnHkc9u5fAeKPAj90BDr9H9CRl2yIqkz7d4Ckc8Dz055dtjyenw4o84EDnwE7ZwIGRkDg2Mp5LX2Tlwncf9RSZ2wB1KlXfKgDHrXKPWqZkxsCls7S5dm024DCEjBUVEm1a4KbN29i165d6NixI3Jzc7FkyRJcv34dr7zyiq6rVu0w2Ok7lQqI2Qzs+wSo0wAYtk5abukMjDvw7OZ+czugwQvSo1DaHanF7/xG6Q8XEVUdjyDg7VOAoXHlvUanmYAyT5qtYts0KdwFjKq81yut7IdSYDIwenbZqqYOdcpHoa6+5qXX0jB3lG6TycsAUm4Cdt7V5pKsrsnlcoSFhWHatGkQQqBZs2bYs2cPmjRpouuqVTsMdvrsyh5gz1yplQ0AslOAjLuAxaN5/cr7B8PKFXh5pdTaVzfg8fJrBwAbD4Y9Im0SAgifC/j2BVz9pWWVGeoA6W9D59lSy13EEuDvKYDcCGg5TDv7V6mke3njjgLxkUB6gtSBoPc3j8t8FywFpTE7paFcAOBkGBD5I/DKumeP0VeV8rKeCHXm5Qt1gHTebTyAuxeloJiZDFg4PXu7WsDd3f2pHq1UNAY7fZSeBGyf/nheSGNL6dJr8FtS8762uD0xkGX2Q2DDa9InzRFbpFYFIqoYIYBdH0rh6sRKYHKU1IuyKshkQNf/SeEu8nvgrwlS4HBqBjTuVrbe8nlZ0v278UeBuGNSmMtN1SyT9Z/pppR5gDIXyM9+vKwgT7pMubIH8MpawDO4/MenLXlZj+6pUwJG5tKVkfKEukKGCqnzRGo8kJYAKKzKNjYh1XoMdvpECOD0b9I/gpxUqbdV0JtAh3elS6qVKS8TcPKVQmXhp2siqph9n0ihDgC6zK26UFdIJgO6fwao8oETK4Ajj1rUpkQ/DnZHlwGXdwH+wwC/R5Oi5+cAl3c+CnFHpftzVQWa+zYylz4cejwH2DV8urPAq39Kf8MsHB8vCxoHXN0r7fO3vsCgX4FGuhkUWC037XGos6tgqCtkZif9Dc9NAx7eBBwaSR0s9J0QQH6Wdnp512IMdvri/lXg78lShwgAcPEHen9bdb1Wrd2klrrMu48vEynzpUnHn3vr8eXfqpKWAFz8B3D0BbzaVe1rE2nDv19IDwDo/rnu7nGTyYAeX0p/U25FAinxgKXr4/W3T0phq36nx8vuXQLWjdDcj6WrFOI8ngPcg6SWP4MS/gUVNbabqS0wfBOwfpQUHFcPlebFbTGk/MdXURZOUscHUxvthDrg8SXZ5AvS/L/pSYCVi3b2XV2plMCDa1Ijgb03w10FMNjVdIX3wOxfABTkAIamwIsfSi11Jf3RrAwymean64ilwKFF0j0xlXEp+L9S4oELf0uXoOOPARBAswGPg13CWSA5Rrf/BIhK48iSx0OOdJkHBL2h2/rI5UDASOnxX8ETpVD35P22GclScPN4ThoaySNIGsJDGx0BjM2AIauAvyZK421uekO6jFuVw7I8jHs88LBMVjlDkxgYATbuwMMbQEaiNKuIPocdmVwKyDKZdBke5lLYS4kDLF0AI5Nn7kIn1OMRVp9OLgx2NVluBrCyG5AoTXeC+i8AL31VfToveHWQPuUnRAH7P5Xu0+nwLtB6jPZ+SR9cBy5skcLc7ZOa69yDAM9HoS4jGVg1EMhIki7vNH9ZO69PpG2RPwK7PpC+7/R/1X+QYFf/x506CnmHSI/KYmAE9F0mTal29DtpWJas+9KH2sr+B3s3Ftg4Fgj8GFB5Ve5rmdoC2alAzsNHl2R9Sh4+paYpvDxfGOis3aVlhf8f0u5Iw3TlpknrzOrorKpFKsiRGhRMbQDzKr4qVYJq8ROydOlSeHl5wcTEBEFBQYiMjCy2bKdOnSCTyZ569OzZswprXE0oLAD7xtIvf9/l0iWK6hLqAMAtABi7D3g5TLqHJus+sPP/gG9bSb3blPll36cQ0v06B74Avn8e+MYf2D3rUaiTSUGu++fA1AvSwMttxkjbmdlLLXWOTQHvLto7RiJtOvWrNLwIALSfCnR8T7f1qc7kciD0U+DFj6TnBxcC/7wjtfJUpuyH0j90oXrcWlOZrN2kHsnKXCD9TuW/XlXJTZdCckr84/NoYKj5od/SSRo6Rqik4V9S4ir//S0tlRK4e0nqMJieKPX0riZ0HuzWrl2LqVOnYvbs2Th16hRatGiB0NBQJCcnF1l+48aNSEhIUD/OnTsHAwMDvPxyLWmBubpPun+sUPfPgQnHAf+h1aopWE0uB5r2A946Jt3zZ+Um9Wr7ezKwNAiI3lD6X4j4SOBLHynQ7fufFPBkcqBeR6DnIuDdWGD0NumylZWr5rZyuXRJa8wu6dNVIeV/bugm0pWz64Atk6Tvn3sL6Dyrev5OVycymTRQ80uLAciAkyuBDaOBglztvUbyBWD/Z4/Dh8dzUmuhuWPV3O5iYCjdbweZdA9fNZgsqlOnTpgyZYr6uZeXFxYvXlziNjKZDJs3b5ZCWtptqSexMk/qLPHfjjWFDIylRgELZ+l51n3IDAyxecM6rRxHcebMmQN/f/+SC8kNHgVPS2kO4GrUkqrzmixatAhjx47F6NGj4evri+XLl8PMzAwrVqwosnydOnXg7OysfuzevRtmZma1I9jdPAL81k8ayqSQuV3Vd0woDwNDoNUI4O2T0jRFZnbSXIp/jpGC2qWdmn+wHlwHDn8DnN/0eJltPelSqpG5NJ1Sr2+AaZeBkVukljnLUoz3pLB4/H3Ed8AvvaRP4ES6dH4zsOlNAAJo/ZrUEsVQV3qtR0tXBgyMpdsyVr2sOUxKecQflzpnfPecdCvJzSOP1zk1rdp/5CZWgGMT6V6zCvxc9OrVC926dSty3cGDByGTyXD27Nky7/f48eMYN27cswsW5EqtXBmPGm7M7KTLy0UMOK0OVzKZ1HHEriEgN0TC6V3o3rqedAWoKqmUQOpt6RaoQuaOUk/oajZDiE7vscvLy8PJkycxc+ZM9TK5XI6QkBBERESUah8///wzhgwZAnPzom8qzc3NRW7u409v6enpFau0LmUkSb8IBXlSS1NVd47QBiMT6SbnVsOlYRKOfAskRQN/DAK8Q6WxqWQyafiE3R9J9+k17Sdta+EAjNkt9fSt6C9S1gPgwAJpSIEV3aShFaxr8dzBpDs3I6QPOEIpDRnS40uGuvJo2ldqjV8zTOpRa1iO+3iFkHr4Hvrq8QgDkAFNekl/e3Xpyb95QpTrZ2TMmDEYMGAAbt269dR8oytXrkTr1q3RvHnZR1JwcHhG40Lhh/a0O0BBI+k+ZxsPzasnz6KwBBx84Gxo8mhmjjgpZFm7aa83ckkykqQBo3NSAUcf6WpRNf091WmL3b1796BUKuHkpNnS4uTkhMTExGduHxkZiXPnzuH1118vtsz8+fNhbW2tfvj6+la43jrTtB8w5SzQb3nNDHVPUlhK9w9NPgO0nST9EXYPfPyL4t0VaBgi/bF+knsb7Xw6MqsDjNomfQK+exH4qQuQFFPx/RKVlWtLoGEXoNlA6XaFanRJp8ap3wkYt1/qRFb4t+Sfd4CfQoDLex6XS7sjXQ24cRi4d1lqtT+/GfihE/B7fynUyQ0B/1eBCZHA4N+kf+bVQX62dG9aduqzy/7HSy+9BAcHB4SFhWksz8jIwPr16zFmzBjcv38fQ4cORd26dWFmZgY/Pz+sXr26xP3+91Ls5cuX8fzzz8PExAS+vr7YvWnVozVC+tvv2AQz5sxHo0aNYGZmhvr16+Ojjz5Cfr5033VYWBjmzp2LM2fOqO+jDwsLAwyMIHNohM0HoqTdZT9A9L//4MWOHWBqago7OzuMGzcOGRmPW9VGjRqFvn37YuHChXBxcYGdnR0mTJigfq3SUKlUmPfVD3Br3R0Kj5bwb9kKO3bsUK/Py8vDxIkT4eLiAhMTE3h6emL+/PnSEQuBOXPmwMPDAwqFAq6urpg0aVKpX7s8anQ6+Pnnn+Hn54fAwMBiy8ycORNTp05VP799+3bNDnfG5vrV5d2sDtD1Y+meIhOrx8vr1JNa0SqTczOpBfD3AcC9WKnlbugfgFf7yn1doicZmUgD7cpkVdPyoO/svTWfJ0YDt45L48EViouQZsopipEZ0Gok0HZi+Vrx8zLLvo2B4vGHdWWB1FFCJteccaJwv+l3gOwH0r1p9o00by95BkNDQ4wYMQJhYWH44IMPIHsUftevXw+lUomhQ4ciIyMDAQEBmDFjBqysrLB161YMHz4cDRo0KPF/bSGVSoX+/fvDyckJx44dQ2rCNUyZ/n/SSjM7aWYOmQyWlpYICwuDq6sroqOjMXbsWFhaWuK9997D4MGDce7cOezYsQN79kiB3Nr6iZlOTG0Bu4bIvH0BoUNeR3BAcxzf+huSVdZ4fdwbmDhxokZ43bdvH1xcXLBv3z5cuXIFgwcPhr+/P8aOHVv0QQghXXp9eAOw8cTXX3+NLxd9he+XL0fLVq2wYsUK9O7dG+fPn4e3tze++eYbbNmyBevWrYOHhwfi4+MRHx8PAPjzzz/x1VdfYc2aNWjatCkSExNx5syZUr9n5aHTYGdvbw8DAwMkJSVpLE9KSoKzs3OJ22ZmZmLNmjWYN29eieUUCgUUisctPGlpaeWvsK7cOQ2k3pLuK9PXT/O6GnzTxh14bYd0L038Uekexpe+Apr01gyaRNoUfxy4tF3q0SmTVf7cr7VZj4XS9FxubR4vM7YEPIKle70y70rDaZjYSB2vAt+o2Ew9n7o+u8x/vRz2+JaTi39LAzB7tgdGb31cZrFf0feVzSlby91rr72GL774AgcOHECnTp0ASJdhBwwYoL6yNW3aNHX5t99+Gzt37sS6detKFez27NmDixcvYufOnXC1UQAOKnz6/gR0f/VtabaSR2Hyww8/VG/j5eWFadOmYc2aNXjvvfdgamoKCwsLGBoaFp8FFJb4Y/cp5OQW4Ncln8Pc0gqw98aSJUvQq1cvfPbhFDi5uAFCwNbWFkuWLIGBgQF8fHzQs2dPhIeHS8FOpZJCf36W1BqanyVddlXmSS25JtZYuHAhZsyYgSFDhwIAPvvsM+zbtw+LFy/G0qVLERcXB29vb7Rv3x4ymQyenp7qasbFxcHZ2RkhISEwMjKCh4dHqc5jReg02BkbGyMgIADh4eHo27cvACnth4eHY+LEiSVuu379euTm5uLVV1+tgprq2J45wLX9QMf3gRdmPqs0lZVZHWDEZuDP16XZKv6aIA1+6ugrXfp1C5TGxLNvWP7XyM+WPgGW4dM16amsB9KYijkp0q0AgcW0GpB2FDXOXqOu0qNQfo50A39NbTF9FEBKM+2Yj48P2rZtixUrVqBTp064cuUKDh48qG4kUSqV+PTTT7Fu3Trcvn0beXl5yM3NhZmZWamqcuHCBbi7u8PVzlKaEQlA8PNPj2m4du1afPPNN7h69SoyMjJQUFAAK6uyfZi+EHsJLfz9YV4vQD0MSrt27aBSqRB79gSczAQgVGjatCkMDAyk3rf5OXCxt0b0ufOPZvbIKWLPAoAMsHRGWp4Md+7cQbt2mjMYtWvXTt3yNmrUKHTp0gWNGzdGt27d8NJLL6FrV+nn6+WXX8bixYtRv359dOvWDT169ECvXr1gaFh58Uvnl2KnTp2KkSNHonXr1ggMDMTixYuRmZmJ0aNHAwBGjBiBunXrqq9XF/r555/Rt29f2Nnp+IbWyhZ3TAp1ckPA/xVd10Z/GZlKl8P2zwfOrAVS44Dk89LjZJh0H9S4/Y/L3zoBODTWnEnj1gnpfp20248ed6ReVGm3pUsnMrkUEr1DpHsInZtX25tvqRKZ1ZGG3jm7lr/T1YU2ZzX4v3KMNWfwxH3DPr2kffw3pE2JLnrbrAfSGG9GZo86jTz7HuQxY8bg7bffxtKlS7Fy5Uo0aNAAHTt2BAB88cUX+Prrr7F48WL4+fnB3NwcU6ZMQV5eXtmOKSUegABMbAG5jcaqiIgIDBs2DHPnzkVoaCisra2xZs0afPnll2V7jSf9N5Sb2QGmdQC5AYyMHvW6fXgTyE2DLC8TqoK8x6FObiidPyNT6au5g/QzYekClOIqX6tWrXD9+nVs374de/bswaBBgxASEoINGzbA3d0dsbGx2LNnD3bv3o233npL3WKqrpeW6TzYDR48GHfv3sWsWbOQmJgIf39/7NixQ92hIi4uDvL/XH6MjY3FoUOHsGvXLl1UuWod+Ez62mIoYOtZclmqGLmBNHL9ix9KA07GR0pzY8Yflzp2FMrPBlaESuMxvRPz+DLynjlP9KQrglBJl3vjj0rTRVk4Ay9+IA0DQ7VLwEig5as1t4WIilfRe6ANDIvuHFfcflVKqZdpfpbUqcLWU2q9K8GgQYMwefJk/PHHH/j1118xfvx49f12hw8fRp8+fdRXw1QqFS5dulTqe9ObNGmC+Ph4JOSZwcXSHLB2x9FduzXKHDlyBJ6envjggw/Uy27evKl5uMbGUCpLHoy4SZMmCAsLQ2ZmpnpkjMOHD0Mul6Nxy7aA7RMdM1VKaVBkuZEUfg2MgTr1pTAnN9L8kC1/fP6trKzg6uqKw4cPq8Nv4es8eUnVysoKgwcPxuDBgzFw4EB069YNDx48QJ06dWBqaopevXqhV69emDBhAnx8fBAdHY1WrVo9+4SWg86DHQBMnDix2Euv+/fvf2pZ48aNIarBII2V7tYJ4Gq49Evb4V1d16Z2sXQGfHtLj/9KvSVNaK7Mk8oVqhsg/aO2qvvo4SrdfF34fW46cGU3cHk3cO2ANP+j0ROXN+5dlua6bdQNcKrBHXzoaam3ge3vAb2+fjyvKEMdaYOJlTQW3MPrUrh7cE2as9vStdgrAhYWFhg8eDBmzpyJtLQ0jBo1Sr3O29sbGzZswJEjR2Bra4tFixYhKSmp1MEuJCQEjRo1wsgx4/DFF18gLS1OI8AVvkZcXBzWrFmDNm3aYOvWrdi0aZNGGS8vL1y/fh1RUVFwc3ODpaWlxv3yADBs2DDMnj0bI0eOxJw5c3D37l28/fbbGD58+FOjbUBuIA2VJZNLwdfA+JkBuND06dMxe/ZsNGjQAP7+/li5ciWioqKwapXU23fRokVwcXFBy5YtIZfLsX79ejg7O8PGxgZhYWFQKpUICgqCmZkZfv/9d5iammrch6dt1SLYUTH2L5C+thhavaYKq+3svYF3oqXxjJ78w9llbsnbmdpIg8+2fk0aqPPmEaDuE5/YYv4C9n4s9eAb+mh4gcIp1Jya1fwhbmqrjLvAr32A+5ele3xeWavrGpG+MTSW/i6l3ZE6g2QkS71obb2kAFOEMWPG4Oeff0aPHj3g6vq4w8eHH36Ia9euITQ0FGZmZhg3bhz69u2L1NRndNIQAnhwHXLTOti0aRPGjBmDwMBAeHl54ZtvvtEYGLl379545513MHHiROTm5qJnz5746KOPMGfOHHWZAQMGYOPGjXjhhReQkpKClStXagRQADAzM8POnTsxefJktGnTBmZmZhgwYAAWLVpUdB1LcQ9iUSZNmoTU1FS8++67SE5Ohq+vL7Zs2QJvb6kHtqWlJT7//HNcvnwZBgYGaNOmDbZt2wa5XA4bGxssWLAAU6dOhVKphJ+fH/7+++9KvY1MJmpF09djt27dgru7O+Lj458aoLFauXUS+OlFqbXu7RNSkzHptwv/SHOF+vYBWg6Tlt2/Ks2ta2QudeRwf06a0sitteb9fVQ9ZT8EwnpJg3Bb1ZV6YNt46LpWVEE5OTm4fv066tWrBxMTLd6fpw3ZD6XBe4VKuqRo61U1fysy7gJpt6Tw5NiUH0TLoaSfq7JkF5756qrw3rrmgxnqaosmL0mPJz28DiispOEYru2XHoD0x9PZTwp6nsHSwKymtlVcYSpRbro0tVVStDT10IgtDHVU+UxtAUNTaQy2gmxpTlYLZ6kzQWUOq2NuJ72ewoqhTsd49qujO6eByzulf97PT3t2edJfDUOAGTekbvnxR4G4o1JP6dQ46RJtwhkg8nupZdc9UCrv3VUKfRXpcZv1QLqUY+OutUOpVfKzpbERbx2Xxkcbsbliw+UQlYWRiTR4cVq89LuckSg9DBTSJdsi5matMJmcH1yqCQa76ujA59JXv5elCYapdpMbSLNkODcD2jyaPi/19uOgd+2ANHNGXIT0OPWrNFVboYLc4odAUCmly71J0UDSeSDxHJB0ThqiBZAGxe42nz2yy6IgD1g3UuohbWwBvLpRmjSeqCrJ5YCNpzQYc+ZdqWNF4eXZQqm3pWXm9pqzXJRWboY0HqNVXQ7dVI0w2FU3CWeA2G2PWuum67o2VF1Z1wWsBwDNBkjPH9581ON2j/SJvPCPrLIAWNQEcGgCvLxS6i0HAP9MBe6cKmGATgCQAbFbpZ7ZHd6V5vTV5nhf+kilBDaNk1rcDU2kjhJuAbquFdVmZnWkh6pA+tBR+LdBCGl8TVWB5m0c2SlAXgaAR+XUgU32aNETzzOSAKGUwuKTIwSQTjHYVTeFrXXNBjw95yFRcWw9pda8wha9QglR0jREyTHSPTaF4o9JLXOANOSKo6/UquTsJ311air1sNs2XWp5OvyNNN6eEf94Fys/G9g6TZpcXm4EDF7FeYep+pAbAsb/+Zdv7S6FOOMnhl3KTQey7pV+v4UD+lK1wWBXnahUgIWT9EmfrXWkDW6tgUlR0thWT46bVvjz5dRMGkqnqDHVTKyBkX8D5/6UQsuTn8gzkh+3/ulaTpo0FVx8JODZThp7sBSj72vVP1OBM6uly10yOTDwZ2mGEdJrKpVK11UoP5lMGoLJ1EZzucLq0d8DIc2shUcDZwjxn+8hhUULJ47JqCXa+nlisKtO5HLgpUXSzAdmdXRdG9IXdeo9PQ5i076l21YmA/wGai67Ei51DHh+OtBRRx9AlPlSPc6ulW5dKLycfPp3oMELlRvsMpKBy7uAFq9Iv7PAozkoswArNyD0f9KQNaS3jI2NIZfLcefOHTg4OMDY2Fg9c0ONJ1MAxmX4/ckvkB5UbkII5OXl4e7du5DL5TA2rljvZQa76oihjqqzmL8AZa50f05VEkLqZXp2LXBuo+br23kD9Z6XWrsLZ3YAgN2zpPl5G3XTzhAMygJgSWtpcGr7xtLYggAQPBFoPRpw8edN5LWAXC5HvXr1kJCQgDt3yjE3LFERzMzM4OHh8dQ0qmXFYFddRCyV7sdxaaHrmhCVrNfXQMPO0th5hRKjgfObpVBlZi+NaWVm/+i5XcVa0O5dBs6uA6LXSWNzFTJ3lFoTmw8qOlAlXwQOfy0NBTMlWupw8iy56VIv4ftXpMvX969KYwgO+UPav4Eh0LAL8OCq1EJXyKFR+Y+PaiRjY2N4eHigoKDgmXOaEj2LgYEBDA0NtdLyy2BXHSRfBHY+mktv8hkOLUHVm0ymealRCGD7DODm4eK3UVhJAc/cXuqBJ5NLY+4FjpXW56QBf46Rvh+69vElzu0zgGPLH+/HyBxo0ksKc/U6ltwKZ2INtJsitew9GeoOfCENHaMqkALc/avS48FVqZdfUZIvPJ6/t9/yyhkHjGocmUwGIyMjGBnx54GqDwa76sDIROoFqypgqKOaJzddar1z9JV602Xek3riFn4VSqnVKzdNmkmjkKXL4+9VBdJ9a/+VkSy1uDXsLM3C0rg7YGxeunpZuTw9f++D68C+/5W8nZk9YNdQGkPSrgFQpwFg9XguTYY6IqrOGOyqA1svqRedis35VAOZWAEd3yt6nUolDWD6ZNDLSZFa+Z4czsfYHOjznfT9k5cinnsL6P45YKGl4RQMjIHAccClHVILol1DKbjZNQTs6kvf/7eXIBFRDSITorDfcu1Qlol0K93NI9K9QU+OIURERET0hLJkl4p1vaDyO7sO+KUXsH6kNHQDERERUQUx2OnC0eXAxrHSfUUmNrquDREREekJ3mNXlYQA9n0K/Pto2rCgN4HQ+Y97ABIRERFVAINdVVEpgW3TgBMrpOcvfAg8P42DmRIREZHWMNhVhYI8YNM4aXJwyICeC5+erJ2IiIioghjsKltuBrBuOHB1LyA3Avr/ADTrr+taERERkR5isKtMWQ+AVS8Dt09II+YP+R1o8KKua0VERER6isGusqTeBn7rB9yLlaZQGrYBcGut61oRERGRHmOwqwxCAOtGSKHO0hUYvglw9NF1rYiIiEjPcZyNyiCTAb0WA3VbA2N2MtQRERFRlWCLXWVx9gNe38PhTIiIiKjKsMWuMjHUERERURVisCMiIiLSEwx2RERERHqCwY6IiIhITzDYEREREekJBjsiIiIiPcFgR0RERKQnGOyIiIiI9ASDHREREZGeYLAjIiIi0hMMdkRERER6gsGOiIiISE8w2BERERHpCQY7IiIiIj3BYEdERESkJxjsiIiIiPQEgx0RERGRnmCwIyIiItITDHZEREREeoLBjoiIiEhPMNgRERER6QkGOyIiIiI9wWBHREREpCcY7IiIiIj0BIMdERERkZ7QebBbunQpvLy8YGJigqCgIERGRpZYPiUlBRMmTICLiwsUCgUaNWqEbdu2VVFtiYiIiKovQ12++Nq1azF16lQsX74cQUFBWLx4MUJDQxEbGwtHR8enyufl5aFLly5wdHTEhg0bULduXdy8eRM2NjZVX3kiIiKiakanwW7RokUYO3YsRo8eDQBYvnw5tm7dihUrVuD9999/qvyKFSvw4MEDHDlyBEZGRgAALy+vqqwyERERUbWls0uxeXl5OHnyJEJCQh5XRi5HSEgIIiIiitxmy5YtCA4OxoQJE+Dk5IRmzZrh008/hVKpLPZ1cnNzkZaWpn6kp6dr/ViIiIiIqgOdBbt79+5BqVTCyclJY7mTkxMSExOL3ObatWvYsGEDlEoltm3bho8++ghffvkl/ve//xX7OvPnz4e1tbX64evrq9XjICIiIqoudN55oixUKhUcHR3xww8/ICAgAIMHD8YHH3yA5cuXF7vNzJkzkZqaqn7ExMRUYY2JiIiIqo7O7rGzt7eHgYEBkpKSNJYnJSXB2dm5yG1cXFxgZGQEAwMD9bImTZogMTEReXl5MDY2fmobhUIBhUKhfp6WlqalIyAiIiKqXnTWYmdsbIyAgACEh4erl6lUKoSHhyM4OLjIbdq1a4crV65ApVKpl126dAkuLi5FhjoiIiKi2kSnl2KnTp2KH3/8Eb/88gsuXLiA8ePHIzMzU91LdsSIEZg5c6a6/Pjx4/HgwQNMnjwZly5dwtatW/Hpp59iwoQJujoEIiIiompDp8OdDB48GHfv3sWsWbOQmJgIf39/7NixQ92hIi4uDnL54+zp7u6OnTt34p133kHz5s1Rt25dTJ48GTNmzNDVIRARERFVGzIhhNB1JarSrVu34O7ujvj4eLi5uem6OkREREQlKkt2qVG9YomIiIioeAx2RERERHqCwY6IiIhITzDYEREREekJBjsiIiIiPcFgR0RERKQnGOyIiIiI9ASDHREREZGeYLAjIiIi0hMMdkRERER6gsGOiIiISE8w2BERERHpCQY7IiIiIj3BYEdERESkJxjsiIiIiPQEgx0RERGRnmCwIyIiItITDHZEREREeoLBjoiIiEhPMNgRERER6QkGOyIiIiI9wWBHREREpCcY7IiIiIj0BIMdERERkZ5gsCMiIiLSEwx2RERERHqCwY6IiIhITzDYEREREekJBjsiIiIiPcFgR0RERKQnGOyIiIiI9ASDHREREZGeYLAjIiIi0hMMdkRERER6gsGOiIiISE8w2BERERHpCQY7IiIiIj3BYEdERESkJxjsiIiIiPQEgx0RERGRnmCwIyIiItITDHZEREREeoLBjoiIiEhPMNgRERER6QkGOyIiIiI9wWBHREREpCcY7IiIiIj0BIMdERERkZ5gsCMiIiLSEwx2RERERHqiWgS7pUuXwsvLCyYmJggKCkJkZGSxZcPCwiCTyTQeJiYmVVhbIiIioupJ58Fu7dq1mDp1KmbPno1Tp06hRYsWCA0NRXJycrHbWFlZISEhQf24efNmFdaYiIiIqHrSebBbtGgRxo4di9GjR8PX1xfLly+HmZkZVqxYUew2MpkMzs7O6oeTk1MV1piIiIioetJpsMvLy8PJkycREhKiXiaXyxESEoKIiIhit8vIyICnpyfc3d3Rp08fnD9/viqqS0RERFSt6TTY3bt3D0ql8qkWNycnJyQmJha5TePGjbFixQr89ddf+P3336FSqdC2bVvcunWryPK5ublIS0tTP9LT07V+HERERETVgc4vxZZVcHAwRowYAX9/f3Ts2BEbN26Eg4MDvv/++yLLz58/H9bW1uqHr69vFdeYiIiIqGroNNjZ29vDwMAASUlJGsuTkpLg7Oxcqn0YGRmhZcuWuHLlSpHrZ86cidTUVPUjJiamwvUmIiIiqo50GuyMjY0REBCA8PBw9TKVSoXw8HAEBweXah9KpRLR0dFwcXEpcr1CoYCVlZX6YWlpqZW6ExEREVU3hrquwNSpUzFy5Ei0bt0agYGBWLx4MTIzMzF69GgAwIgRI1C3bl3Mnz8fADBv3jw899xzaNiwIVJSUvDFF1/g5s2beP3113V5GEREREQ6p/NgN3jwYNy9exezZs1CYmIi/P39sWPHDnWHiri4OMjljxsWHz58iLFjxyIxMRG2trYICAjAkSNHeO8cERER1XoyIYTQdSWq0q1bt+Du7o74+Hi4ubnpujpEREREJSpLdqlxvWKJiIiIqGgMdkRERER6gsGOiIiISE8w2BERERHpCQY7IiIiIj1RrmAXHx+vMTdrZGQkpkyZgh9++EFrFSMiIiKisilXsHvllVewb98+AEBiYiK6dOmCyMhIfPDBB5g3b55WK0hEREREpVOuYHfu3DkEBgYCANatW4dmzZrhyJEjWLVqFcLCwrRZPyIiIiIqpXIFu/z8fCgUCgDAnj170Lt3bwCAj48PEhIStFc7IiIiIiq1cgW7pk2bYvny5Th48CB2796Nbt26AQDu3LkDOzs7rVaQiIiIiEqnXMHus88+w/fff49OnTph6NChaNGiBQBgy5Yt6ku0RERERFS1DMuzUadOnXDv3j2kpaXB1tZWvXzcuHEwMzPTWuWIiIiIqPTK1WKXnZ2N3Nxcdai7efMmFi9ejNjYWDg6Omq1gkRERERUOuUKdn369MGvv/4KAEhJSUFQUBC+/PJL9O3bF8uWLdNqBYmIiIiodMoV7E6dOoUOHToAADZs2AAnJyfcvHkTv/76K7755hutVpCIiIiISqdcwS4rKwuWlpYAgF27dqF///6Qy+V47rnncPPmTa1WkIiIiIhKp1zBrmHDhti8eTPi4+Oxc+dOdO3aFQCQnJwMKysrrVaQiIiIiEqnXMFu1qxZmDZtGry8vBAYGIjg4GAAUutdy5YttVpBIiIiIiqdcg13MnDgQLRv3x4JCQnqMewAoHPnzujXr5/WKkdEREREpVeuYAcAzs7OcHZ2xq1btwAAbm5uHJyYiIiISIfKdSlWpVJh3rx5sLa2hqenJzw9PWFjY4OPP/4YKpVK23UkIiIiolIoV4vdBx98gJ9//hkLFixAu3btAACHDh3CnDlzkJOTg08++USrlSQiIiKiZytXsPvll1/w008/oXfv3uplzZs3R926dfHWW28x2BERERHpQLkuxT548AA+Pj5PLffx8cGDBw8qXCkiIiIiKrtyBbsWLVpgyZIlTy1fsmQJmjdvXuFKEREREVHZletS7Oeff46ePXtiz5496jHsIiIiEB8fj23btmm1gkRERERUOuVqsevYsSMuXbqEfv36ISUlBSkpKejfvz/Onz+P3377Tdt1JCIiIqJSkAkhhLZ2dubMGbRq1QpKpVJbu9S6W7duwd3dHfHx8XBzc9N1dYiIiIhKVJbsUq4WOyIiIiKqfhjsiIiIiPQEgx0RERGRnihTr9j+/fuXuD4lJaUidSEiIiKiCihTsLO2tn7m+hEjRlSoQkRERERUPmUKditXrqysehARERFRBfEeOyIiIiI9wWBHREREpCcY7IiIiIj0BIMdERERkZ5gsCMiIiLSEwx2RERERHqCwY6IiIhITzDYEREREekJBjsiIiIiPcFgR0RERKQnGOyIiIiI9ASDHREREZGeYLAjIiIi0hMMdkRERER6gsGOiIiISE8w2BERERHpCQY7IiIiIj1RLYLd0qVL4eXlBRMTEwQFBSEyMrJU261ZswYymQx9+/at3AoSERER1QA6D3Zr167F1KlTMXv2bJw6dQotWrRAaGgokpOTS9zuxo0bmDZtGjp06FBFNSUiIiKq3nQe7BYtWoSxY8di9OjR8PX1xfLly2FmZoYVK1YUu41SqcSwYcMwd+5c1K9fvwprS0RERFR96TTY5eXl4eTJkwgJCVEvk8vlCAkJQURERLHbzZs3D46OjhgzZkxVVJOIiIioRjDU5Yvfu3cPSqUSTk5OGsudnJxw8eLFIrc5dOgQfv75Z0RFRZXqNXJzc5Gbm6t+np6eXu76EhEREVVnOr8UWxbp6ekYPnw4fvzxR9jb25dqm/nz58Pa2lr98PX1reRaEhEREemGTlvs7O3tYWBggKSkJI3lSUlJcHZ2fqr81atXcePGDfTq1Uu9TKVSAQAMDQ0RGxuLBg0aaGwzc+ZMTJ06Vf389u3bDHdERESkl3TaYmdsbIyAgACEh4erl6lUKoSHhyM4OPip8j4+PoiOjkZUVJT60bt3b7zwwguIioqCu7v7U9soFApYWVmpH5aWlpV6TERERES6otMWOwCYOnUqRo4cidatWyMwMBCLFy9GZmYmRo8eDQAYMWIE6tati/nz58PExATNmjXT2N7GxgYAnlpOREREVNvoPNgNHjwYd+/exaxZs5CYmAh/f3/s2LFD3aEiLi4OcnmNuhWQiIiISCdkQgih60pUpVu3bsHd3R3x8fFwc3PTdXWIiIiISlSW7MKmMCIiIiI9wWBHREREpCcY7IiIiIj0BIMdERERkZ5gsCMiIiLSEwx2RERERHqCwY6IiIhITzDYEREREekJBjsiIiIiPcFgR0RERKQnGOyIiIiI9ASDHREREZGeYLAjIiIi0hMMdkRERER6gsGOiIiISE8w2BERERHpCQY7IiIiIj3BYEdERESkJxjsiIiIiPQEgx0RERGRnmCwIyIiItITDHZEREREeoLBjoiIiEhPMNgRERER6QkGOyIiIiI9wWBHREREpCcY7IiIiIj0BIMdERERkZ5gsCMiIiLSEwx2RERERHqCwY6IiIhITzDYEREREekJBjsiIiIiPcFgR0RERKQnGOyIiIiI9ASDHREREZGeYLAjIiIi0hMMdkRERER6gsGOiIiISE8w2BERERHpCQY7IiIiIj3BYEdERESkJxjsiIiIiPQEgx0RERGRnmCwq0GUKoHt0Qm4nZKt9X0fvnIP1+5maH2/REREVHUMdV0BKp3sPCUmrTmN3TFJcLU2Qfi7nWBqbKCVfe+9mITXwk7AwVKBA9M7wcyYPxZEREQ1EVvsaoD7GbkY+uNR7I5JAgDcSc3B8gNXtbLv3AIl5v0dAwC4m56LXyNuamW/REREVPUY7CpBvlKFeX/HaOWS6c37mRiw7Aii4lNgY2aE8Z0aAACWH7iKWw+zKrz/FYdu4Mb9LBgZyNT7Tc/Jr/B+iYiIqOox2FWCFYeuY8Xh6wj58gC+238FeQWqcu0nKj4F/b87ghv3s+Bma4oNb7bFe6GNEVSvDnILVJi/7WKF6pmcloMley8DAD7p64cGDuZIycrHysM3KrRfIiIi0g0Gu0rwfCMHtPGyRXa+Ep/viEX3r//Fkav3yrSPPTFJGPJDBO5n5qFZXStsfKstGjpaQCaTYU7vppDLgK3RCYi4er/c9Vyw4yIy85Twd7fBwAA3TAlpBAD48eA1pGax1Y6IiKimYbCrBE1crLDujWAsfLkF7MyNcfVuJl758RgmrT6N5LScZ26/6thNjPvtBHLyVejYyAFrxwXD0dJEY/+vBHkAAOb+fR4FyrK3CJ6Ke4iNp24DgBQU5TL09HOBj7Ml0nMK8OPBa2XeJxEREelWtQh2S5cuhZeXF0xMTBAUFITIyMhiy27cuBGtW7eGjY0NzM3N4e/vj99++60Ka1s6MpkMAwPcsPfdThj+nCdkMmDLmTt48csD+PnQ9SLDmBACC3fG4oNN56ASwKDWbvhpZGuYK57upfpul8awNjXCxcR0rD4eX6a6qVQCc7ecBwAMDHCDv7sNAEAul+GdLlKr3YrD13E/I7eMR/20CwlpiLtf8XsBiYiI6Nl0HuzWrl2LqVOnYvbs2Th16hRatGiB0NBQJCcnF1m+Tp06+OCDDxAREYGzZ89i9OjRGD16NHbu3FnFNS8dazMjfNy3GbZMaI8W7jbIyC3Ax//E4KVvD+HEjQfqcnkFKry7/gyW7LsCAJgS4o3PBjSHkUHRb5GtuTGmPgphX+6KRUpWXqnrtOHULZy5lQoLhSHe69ZYY11XXyf41bVGVp4S3/9bsVa7I1fuoec3B9F76aEy1Y+IiIjKR+fBbtGiRRg7dixGjx4NX19fLF++HGZmZlixYkWR5Tt16oR+/fqhSZMmaNCgASZPnozmzZvj0KFDVVzzsvFzs8am8W3xaT8/2JhJLW0Dl0fg3XVncONeJl4LO46Np27DQC7D5wOaY0pII8hkshL3OSzIA42cLJCSlY+vdl8qVT3ScvLx+Y5YAMCkzg01LvECUkvj1K5SYPzlyI1SXTouSlJaDiatOQ2VAFKy8vHdfu0Mz0JERETF02mwy8vLw8mTJxESEqJeJpfLERISgoiIiGduL4RAeHg4YmNj8fzzz1dmVbVCLpfhlSAP7H23Ewa3dgcA/HnqFjot3I9DV+7BzNgAP41sjUFt3Eu1P0MDOWb3agoA+P1YHGIT05+5zbfhl3EvIxf17c0xqm29Ist0auSAVh42yC1QlSuQFShVePuP07iXkQcHSwUAIOzIDdyphBkziIiI6DGdBrt79+5BqVTCyclJY7mTkxMSExOL3S41NRUWFhYwNjZGz5498e2336JLly5Fls3NzUVaWpr6kZ7+7PBT2eqYG+Ozgc2x8a22aOpqBQCwt1Bg7bhgvNDYsUz7atfQHqFNnaBUCcz9+zyEEMWWvXo3Qz2UyUe9fGFsWPTbL5PJMK2rdIn2j2NxZR6P74tdsYi88QAWCkOsHfccgurVQV6BCov3lK5VkYiIiMpH55diy8PS0hJRUVE4fvw4PvnkE0ydOhX79+8vsuz8+fNhbW2tfvj6+lZtZUvQysMWWya2x8rRbbBtcnv4uVmXaz8f9pRC2pGr97HzfNGBWAiBeX/HoEAl8KKP4zMDZNuG9niufh3kKVVYsvdKqeuy63wivj8g3Zv3+cDmqO9ggRndfQAAG07ewuUk3QdrIiIifaXTYGdvbw8DAwMkJSVpLE9KSoKzs3Ox28nlcjRs2BD+/v549913MXDgQMyfP7/IsjNnzkRqaqr6ERMTo9VjqCgDuQwvNHZ86l63snCvY4ZxHeoDAP639QJy8pVPldl7MRkHLt2FkYEMH71UunD77qNWu/Un4kvVszXufhbeXX8GAPBau3ro4ecCQAqw3Zo6QyWAz3fGluq1iYiIqOx0GuyMjY0REBCA8PBw9TKVSoXw8HAEBweXej8qlQq5uUUPzaFQKGBlZaV+WFpaVrje1dFbLzSAs5UJbj3Mxo//6c2aW6DEx/9Igfa19vVQz968VPts41UHzzdyQIFK4OvwyyWWzclXYvyqk0jPKUArDxu8/6iVrtC00MaQy4DdMUkavYGJiIhIe3R+KXbq1Kn48ccf8csvv+DChQsYP348MjMzMXr0aADAiBEjMHPmTHX5+fPnY/fu3bh27RouXLiAL7/8Er/99hteffVVXR1CtWBmbIiZPaQw9d3+q0hIfXxf3MrD0nywDpYKvP2id5n2WzikyqbTt3AlOaPYcnP/jsH5O2moY26MJa+0eur+vYaOFhj0qMPIZzsulngvIBEREZWPzoPd4MGDsXDhQsyaNQv+/v6IiorCjh071B0q4uLikJCQoC6fmZmJt956C02bNkW7du3w559/4vfff8frr7+uq0OoNnq3cEVrT2kqswXbpXlkk9Ny8O2j1rYZ3XxgUcRgxyXxd7dBSBMnqASKbbXbeOoWVkfGQSYDFg/2h6uNaZHlpoQ0gsJQjuM3HmLvxaLHKSQiIqLyk4la1nRy69YtuLu7Iz4+Hm5ubrqujtadu52KXksOQQhgw5vB+CMyDhtP3Ya/uw02jm8LubzksfGKEnMnDT2+OQiZDNg+uQN8nK3U62IT09F36WFk5ysxubO3euaK4izYfhHLD1xFIycLbJ/8PAzKUR8iIqLapCzZRectdqRdzepaq8fIm7I26qn5YMvD19UKPf1cIAQ0BkLOyC3A+FUnkZ2vRAdve0zq/OzLvOM7NoC1qREuJWVg0+nb5aoPERERFY3BTg9NC20MSxND3Hoo3Wf35Hyw5TUlxBsyGbDzfBKib6VCCIEZf57FtbuZcLYyweLB/qVqfbM2M8JbnRoAABbtii2yBy8RERGVD4OdHrK3UGDyo9azouaDLQ9vJ0v09a8LAFi0Oxa/RtzE1rMJMJTLsHRYS9hZKEq9r5FtveBibYI7qTn4/ejNCteNiIiIJAx2empUWy/8Xw8f/DAioEJj5D1pcmdvGMhl2Bd7Vz18ysweTRDgWadM+zExMsA7IdK9eEv2XUFaTr5W6kdERFTbMdjpKUMDOcY93wBtG9hrbZ9e9uYY0EpqtStQCXRv5ozX2nmVa1/9W9WFt6MFUrLy8f2Bss9HS0RERE9jsKMymdTZG1YmhvB2tMBnA5tDJitfhwxDAzmmh0qXiH8+dB3JaTnarCYREVGtxGBHZeJma4ZD77+Iv99uDysTowrtq4uvEwI8bZGTr8LiZ8xsQURERM/GYEdlZmViBBMjgwrvRyaTqaceW3s8HtfuFj+zBRERET0bgx3pVBuvOujs4wilSmDhrlhdV4eIiKhGY7AjnXuvmw9kMmBbdCLOxKfoujpUBkIIfBt+GS9+uR8RV+/rujpERLUegx3pXGNnS/RvKU2RMnNjNI5cuQeVqlbNdFcjCSHw8T8X8OXuS7h2NxMT/jiFOynZuq4WEVGtVrYZ4YkqydSujbD9XAJiEtLwyk/H4GlnhkGt3fFygBscrbQzDl9xktJyEBWfgqj4FJyJT4GFwhBfvNwC1qYV6xyiz1QqgQ//Ooc/jsUBAFysTZCQmoO3Vp3CujeCYWzIz4xERLogE0LUqqaRskykS1XrSnIGwo5cx1+n7yA9twAAYCCXobOPI4YEuqNjI8dSTVtWkszcApy9lYozt1IQFZeCM7dSkJD69FArAZ62+G1MIMyM+dnnvwqUKry34Sw2nr4NmQz4rH9zPFffDi99exBpOQUYGeyJuX2a6bqaRER6oyzZhcGOqp2svAJsPZuANcfjcfLmQ/VyF2sTvNzaHYNau8HN1qzIbYUQSM8tQHJaLu6m5yI5PQd303NxOSkDUfEpuJycjv9e5ZXLgEZOlmjpYQNvR0ss3nMJaTkFaNfQDj+PbKOVHsD6Il+pwpQ1UdganQADuQyLBrVAn0dTzYVfSMKYX04AAL4e4q9eTkREFcNgVwIGu5rlUlI61kTGY+PpW0jJkqYek8mA570d0NLDBvcz8tThLTldCnO5BaoS9+lqbYIW7jbwf/RoVtca5orHLXOn4x7i1Z+OITNPiZAmjlj2agCMDHhpMSdfiYl/nMKeC8kwMpDh26Gt0K2Zs0aZhTtjsWTfFZgaGeCvie3QyMlSR7UlItIfDHYlYLCrmXLyldh5PhFrj8fjSCl6X1qaGMLBUgFHSwUcLE3gbmuKFu42aOluU6p79iKu3seolZHILVChVwtXLB7sX+HLwDVZdp4S4347gYOX70FhKMfy4QF4obHjU+WUKoERK47h8JX7qO9gji0T28NCwcvZREQVwWBXAga7mu/GvUz8eeoW7qbnPhHepABX+L02Lp/uu5iMcb+dQL5SYEgbd8zv71fuKdSqAyEEClSizK2PGbkFeC3sOCKvP4CZsQF+GtEabRsWPwfx/YxcvPTtISSk5qCnnwuWvNKyRp83IiJdY7ArAYMdlcW26ARM/OMUVAJ4rV09fPRSk3KFlHO3U5GUloN2De11cs+eEAIz/jyL9SdvoYmzFYLq10FQPTsE1quDOubGxW6XmpWPkSsjERWfAkuFIcJea4MAzzrPfL1TcQ8x+PsI5CsFPnrJF2Pa19Pm4RAR1SoMdiVgsKOy2nDyFqatPwMAmPRiQ0zt2rhU2wkhcPjKfXy3/4r68rG1qREGBrjhlSAPNHCwqLQ6/9cvR25g9pbzRa5r5GSBoHp2CKpfB4H16sDRUrpUfT8jF8N/jkRMQhpszIzw22tB8HOzLvNrGsplWD3uObTxenYgJCKipzHYlYDBjsrj14gbmPWXFIze7+6DNzs2KLasUiWw63wivtt/FdG3UwEAhnIZ7CyMkZSWqy4XXN8OrwR5ILSpc6WO+3by5kMM+UFqPXu3SyPUczDHsWsPcOz6fVxKenp+3voO5giqVwcnbjzE5eQM2FsY4/fXg+DjbFWm1xVCYPKaKGw5cweOlgpsndQBDpYKbR0WEVGtUZbswruaiUphRLAXMnIL8PmOWCzYfhHmxgYYHuylUSavQIXNp29j+b9Xce1uJgDAxEiOIW088HqHenCxNsW/l+5i1bGb2HsxGRHX7iPi2n3YWxjj5dbueCXQA+51ih7GpbzuZ+RiwqpTyFcK9PRzwcQXG0Imk+Gl5q7q9cdvPMDRaw9w7PoDXExMw7W7mer6O1uZYNXYoHK1LspkMszv74cLCWm4nJyBt1efwu9jgmDIHsZERJWGLXZEZfDFzotYuu8qAODLl1tgQIAbMnMLsDoyDj8dvI7ENGmwYysTQ4xs64VRbb1gZ/F0K9WdlGysOR6PNZFxSE6XWvEKh3F5JcgDnX0cKxyAytNDNTUrH5E3HiDy+n0kpuVietfG8LCrWNi8kpyBPksOITNPiTc7NsD73X0qtD8iotqGl2JLwGBHFSGEwNy/YxB25AbkMmBwG3dsP5eoHmPP0VKB1zvUwytBnqUa5iNfqUL4hWSsOnYTBy/fUy+va2OKb19piVYetuWua3UaU27r2QRM+OMUAOD74QEIber8jC2IiKgQg10JGOyoolQqgfc3nsW6E7fUy7zszPBGxwbo36ouFIbl6/V6834mVkfGY/2JeNzPzIOxoRyfDfBDv5Zl/zmtjrNAfPxPDH4+dB2WCkNsmtAWDR05eDERUWkw2JWAwY60QakSmPv3eVxMTMfw5zzRw89FawMYZ+YWYMraKOyOSQIAjO/UANO7Noa8lPuPf5CFnt9Uv3lb85UqDP3hKE7cfIg65sb49bVANKtb+l62NZEQAtn5SqRk5UuP7DykZuXjYVY+MnML0LWpEzztzLX2evEPsjBx9Wl4O1pgZnefIm8DIKKah8GuBAx2VBOoVAJf7o5V388X0sQRi4e0fObl3Zx8JQYsO4Lzd9Lg726DdW8EV2qP27J6kJmHUSsjcfZWKiwUhvhxRGsEN7DTdbW04m56LhbujMX1e5l4mJWHlOx8pGblI09Z/BR37nVMsXVSB1iZGFX49QuUKgz6PgKn4lIAAHXMjTG7ly96t3DlANFENVxZskv1+YtPRGpyuQzTQ33w9RB/GBvKsedCMgZ8dwTxD7JK3G7OlvM4fycNdcyN8d2wVtUq1AFS2Phj7HMIrm+HjNwCjFwZiV3nE3VdrQpTqgTeXn0Ka0/EI/LGA1xOzsDd9Fx1qDMykMHeQgFvRwu08bJFSBMnOFkpEP8gGzM3RkMbn6+/3XsFp+KkgaR9nC3xIDMPk9dE4fVfTiAhNbvC+yeimoEtdkTVXFR8Csb+egJ303NRx9wYy4a1QlD9p1u51h2Px3t/noVMBvz2WhDaexc/7Zeu5eQrMWn1aeyKSYKBXIbPBjTHwICa+/u4dN8VfLEzFmbGBvikXzM4WprA2tQItubGsDE1gpmxwVOtZqfiHmLQ8ggUqAQW9PfDkECPcr/+iRsPMOj7CKiEdE9l92Yu+P7AVXy79wrylCpYKAwxs4cPhrbxKPUlfSKqPthiR6RH/N1tsGViO/jVtcaDzDy8+vMxrD0ep1Hm3O1UfPTXOQDAu10aVetQBwAmRgb4blgrvBzgBqVKYNr6M/jp4DVdV6tcTsc9xKLdlwAAc3s3Rb+WbmjX0B7N6lqjro0pzBWGRV4KbeVhi2mh0iwmc/4+j0tJ6eV6/bScfExZGwWVAPq3rIs+/nVhbCjH2529sXVSe7T0sEFGbgE+2HQOr/x0FDfuZZb/YImo2mOwI6oBXKxNse6NYPRs7oJ8pcCMP6Mx7+8YFChVSM3Kx1urTiG3QIUXfRzxVqeGuq5uqRgayPH5wOYY20GaR/Z/Wy9g4c5YrVyWrCoZuQWYvCYKSpXAS81dytzqOK5DfXTwtkdOvgoT/ziFnHxlmeswa/M53HqYDfc6ppjbp6nGOm8nS2x4sy1mveQLUyMDHL32AKGL/8UP/15FQQn3/hFRzcVgR1RDmBobYMnQlpjapREAYMXh63jtlxOYsvY04h5kwc3WFF8N8q9Rl9pkMhn+r0cTTH/UcrVk3xV8uPkclKqaEe5mbT6HuAdZqGtjik/6+ZW5k4JcLsOiQf6wt1DgUlIG5v0TU6btN5++jc1Rd2Agl2Hx4JawLKIThoFchtfa18Oud55H+4b2yC1Q4dNtF9F/2RFcSEgr0+sRUfXHe+yIaqBt0QmYui4KOflSq4uxoRwbx7et0cOHrDp2Ex9uPgchgJeau2DRIP9Sdf7IK1Dh2r0MXL+bidTsfGTkFiAtpwAZOQXIyM1Hek7BE8uk9SoBjO1QD2M71C93j9HNp29jytooyGXAujeC0dqrTrn2AwCHLt/D8BXHIASw9JVW6Nnc5ZnbxD/IQo+vDyI9twDvhDTC5BDvZ24jhMD6E7fw8dYYpOcUwFAuw/ONHOBkpYCDpQkcLRVwtFTAwVIBRysTOFgoql0HHKLaiHPFEum5Hn4u8KhjhrG/nkBCag7m9W5ao0MdAAwL8oS1qRHeWRuFf84mIC2nAMtfbQUzY+nPVL5ShRv3MnEpKQOXktJxOTkdl5IycP1eZrla+D7ddhHX72Xh4z5Nyzx9W9z9LHy4WbqncVJn7wqFOgBo722P8R0b4Lv9V/H+xrNo7mZd4rzBBUoV3lkbhfTcArT2tMWEFxqU6nVkMhkGtXFHx8YO+GjzOeyKScLei8klbmNrZiQFPUsT9GtZFwNqcCcXotqALXZENVhGbgHupGTrdLowbTtw6S7e/O0ksvOV8KtrDU87M1xOysC1exnIVxb958pSYYgGjhawMzeGhYkhLE0MYaEwguWj7598bqEwxLHrD/DJ1hioBNCxkQOWDmtVqingAClUvfx9BE7HpaC1py3WjHuuwvP6AlJwHfxoHDp/dxusfzMYRsXs9+s9l/HVnkuwVBhi2+QOJYbA4gghcOLmQ1xOykByeg6S03NxNz1X+pqWg7sZuUWe74Uvt6jRPZiJaiIOUFwCBjui6u/kzYd4Lew4UrPzNZabGxugoZMlGjlaoLGzJbydLNHIyQLOViZlvqS6OyYJb68+hZx8FXxdrLBydBs4WZk8c7tFu2Lxzd4rsDQxxPbJHeBmW/ZQVZwnZw15s2MDvN/d56kyJ28+xKDvI6BUCSwe7I++LStnujghBFKy8nE3IxfJabnYfi4Bq47FwVAuw8rRbdDB26FSXpeInsZgVwIGO6Ka4UpyBtafjIetmTEaOVmgkZMlXK1Ntdo55Ex8Csb8chz3MvLgYm2ClaPbwMfZqtjyx67dx9Afj0IlgG+GtkTvFq5aq0uh7dEJGL/qFADg19cC8XyjxwEqPScfPb45iPgH2ejr74rFQ1pq/fWLo1IJTFkbhS1n7sBCYYj1bwajiUvx54qItIfj2BFRjdfQ0QIzuzfBmx0b4EUfJ7jZmmm9x28LdxtseqsdGjiYIyE1By8vi8Chy/eKLJualY93Ho0XNzDArVJCHQB093PBq89JgxVPXReF5PQc9brZf51H/INsuNmaYl7fqp0DWC6X4YuXm+O5+nWQkVuA0SuPc0YLomqIwY6IajX3OmbYOL4dgurVQXpuAUatjMT6E/EaZYQQmLnpLO6k5sDLzgxzejctZm/a8WFPX/g4W+JeRh6mrj0DlUrgr6jb2Hj6NuQyYPFgf63ML1tWCkMDfP9qa3g7WiAxLQejVhxHWk7+szfUggKlCu//eRaz/joHlRaHw8krUGHkiki0W7AX/7cpGvsuJpdrPEGi6oLBjohqPWszI/w6JhB9/F1RoBKYvuEsFu2+pB4sef2JW9gWnQhDuQxfD2lZ6o4W5WViZIAlr7SEqZEBDl25h3n/xKh74U58seK9cCvC2swIK0e3gYOlArFJ6Rj/+0nkFVT+YMcrD9/AmuPx+DXiJn6JuKG1/S7ZdwUHLt3F7ZRs/HEsDqPDjqPVx7vxxm8nsO5EPO5l5GrttYiqAu+xIyJ6RAiBL3ddwpJ9VwAA/VvVxRvPN0DfpYeRna/E+9198GbH0g0tog2F8/8Waulhg/VvBGulF25FnbudisHfRyAzT4n+Leviy0Etyj0m4LPE3c9C18UH1OM2Kgzl2DqpPRo6Vqw3+Jn4FPRfdgRKlcCUEG/cy8jFnphkJKY9vvwtk0nTv4U0cUIXX0c0cLCotOMkKg47T5SAwY6InmVNZBw+eDQDhpGBDPlKgbYN7PD7mKAqndlDCIHJax53WNg2qQM87LTXC7eiDly6i9fCjkOpEnj7xYZ4t2tjrb+GEALDf47EoSv38Fz9OjAykOPg5Xto7maNP8e3LXZImGfJyVei5zcHcfVuJl5q7oIlr7RSv975O2nYHZOEPReScP6O5uwcnnZm6NXcFW92aqDVltvI6w9wOyULfVrUrVGzx1DV4ADFREQVMCTQAy42pnjr95PIzFPC1swIi3QwXZtMJsOn/f3gYm2Cjo0cqlWoA6QxAOf388N7f57Ft3uvwNXGFEMDPbT6GhtO3sKhK/egMJRjQf/mMDEyQOjif3H2ViqW7L2Cdx5NsVdWX+yMxdW7mXCwVODjPo87oshkMjSra41mda3xTpdGuJOSjfCLydgTk4SIq/dx834Wluy7go2nbuF//ZrhRR+nCh3fvYxcfPxPDP6KugMAuJOSgwkv1Iz5nql6YosdEVExYu6k4ceD1zAsyEOn97VVd4t2X8I34ZdhIJfhp5Gt8UJjR63s9256LkIWHUBqdr7GZfAtZ+5g0urTMJDLsHF8W7RwtynTfo8+GrZGCGDFqNalDmcZuQXYezEZX+y8iPgHUo/gXi1cMeslXzhYKspUB5VKYN2JeMzffhGp2fmQyQAhALkM+G1MENo1tC/T/ki/cbgTIiIt8HW1wleD/RnqnuGdEG8MaOUGpUpgwqpTOHc7VSv7nfP3eaRm56OpqxVeb19Pvbx3C1e81NwFSpXAO+uikJ1X+l6sGbkFmLb+DIQABrd2L1OLm4XCEL1buGLnlOcxtkM9yGXA32fuIGTRAaw7EY/StpNcSU7HkB+O4v2N0erj+2tCOwxq7QaVAN5efZpDyVC5scWOiIgqLK9AhdfCjuPQlXtwsFRg4/i25ZrqrNDumCSM/fUEDOQy/DWh3VNzIadk5aHrV/8iOT0Xo9p6lXoImpkbz2J1ZDzq2phix5QOsKzAsDHRt1Lx/saz6vvw2jaww6f9/OBlb15k+Zx8Jb7bdwXLDlxFvlLA1MgA73ZthFFtvWBoIEdOvhIDlh3B+TtpaOlhg7XjgmFsWLH2l02nb2HDyVvIK1ChQCWgUgkohUCBUkAlhHpZ4VdnaxN8NqA5vPVomkJ9wM4TJWCwIyKqHOk5+Xh5eQQuJqbD084MYaMDUa+YkFOStJx8dFl0AElpucVOrQYA+2OTMWrlcQDA72OC0N675MuX+2KTMfpR+dVjn0NwA7sy1+2/CpQq/HzoOhbtvoTcAhUUhnJMDvHG2A71NTp2HLlyDx9sPofr9zIBAJ19HDG3T9OnpqSLu5+Fl76VppUbEeyJeX3KPxD1sv1X8dmOi2XezsvODH9NbA9r06ofK5GKxmBXAgY7IqLKk5iagwHLjuB2SjZszIzww/DWCKxXtkvZH2yKxqpjcfCyM8OOKc/DxMig2LIfbo7G70fj4GJtgh1Tni82jDzZwvdau3qY1cu3THV6lpv3M/F/m6Jx+Mp9AEATFyt8NsAPdW1M8cm2C9h46jYAwNFSgbm9m6JbM+dih03ZezEJr4WdAIByzQcshMDCXbFYuu8qAGBM+3po42ULuUwGQwMZ5DIZDOSPHk98rxICk1ZH4XZKNl70ccRPI1qzh241wWBXAgY7IqLKlZyeg7G/nMCZW6kwNpDj84HNSx1Ojl27j8E/HAUA/DE2CG0blNwKl5VXgB5fH8SN+1no37IuFg32L7LcpNWnseXMHdR3MMe2SR1KDIvlJYTAn6du439bY5CSlQ+5DDBXGCI9pwAyGfBqkCemd2tcqllDvtwVi2/3XoGpkQE2T2iHxs6luzSqUgnM+ycGYUduAABmdvfBG2UYe/Hc7VQMWHYEuQUqTOrsjanl7HVcm1y/lwkvO7NKHd+QnSeIiEhnHC1NsGZcMLo1dUaeUoUpa6OweM+lZ3YuyMlXYubGaADAkDbuzwx1AGBmbIgvB/lDLgM2nr6N7dEJT5XZejYBW87cgYFchkWD/Csl1AHSUCkDA9ywZ2pH9G7hCpUA0nMK4ONsiT/Ht8XHfZuVeiq4KSGN0MHbHtn5Srz5+0mkl2LqNqVKYMafZxF25AZkMuB/fZuVKdQBQLO61vi0nx8A4Jvwy9gdk1Sm7WubP0/eQujif7HswFVdV0WNwY6IiLTO1NgA3w1rhTeerw8AWLznMqauO4PcguJ7sH679zKu3ZPGlpvZo0mpXyvA0xbjO0kB5v82RSM5/fHMEcnpOfhwsxQW3+rUAP5lHBqlPOwtFPhmaEv88XoQvhjYHH+/3R6tPGzLtA+DR9PXuVqb4Pq9TExff7bEYJxXoMKk1aex/uStRwG2BV59zrNc9R8Q4IaRwdK2U9dG4erdjHLtR58VKFWY93cM3l1/BnkFKkTFpWh1DuOKYLAjIqJKIZfLMLNHE3zazw8Gchk2nb6N4T9HIiUr76myMXfS8P2BawCAj/s0LfON+5M7N4KvixUeZuXj/T+jIYSAEAL/tzEaD7Py4etihbdf9NbKcZVW24b2eLm1e7lnx6hjbozvXg2AsYEcO84n4od/rxVZLudRq97W6AQYGciw9JVW6NeyYrcaffiSLwK96iA9twBv/HYSGbkFFdqfPnmYmYeRKyOx4vB1AMCkFxti+asB1eZ+xGoR7JYuXQovLy+YmJggKCgIkZGRxZb98ccf0aFDB9ja2sLW1hYhISElliciIt16JcgDK0e1gYXCEJHXH6Dfd0dw41HvUEBq/Xh/41kUqAS6NXVGt2YuZX4NY0M5vhrsD2MDOfZeTMba4/FYf/IW9lxIhrGBHIsGt6jw0CG64O9uo+7o8dmOi4i4el9jfUZuAUavPI69F5NhYiTHTyPboFsz5wq/rpGBHEuGtYSTlQJXkjMwbd2ZUo/Tp88uJqah99JDOHzlPsyMDbD81VaY2rVxtQl1QDUIdmvXrsXUqVMxe/ZsnDp1Ci1atEBoaCiSk5OLLL9//34MHToU+/btQ0REBNzd3dG1a1fcvn27imtORESl9XwjB/w5vi3q2pji+r1M9PvuMI7feAAACDtyA2dvpcLSxBDz+pRuPLqiNHa2xPRQab7aef/EYN7fMQCAd7o0go+zVcUPQkeGBXmgf8u66sGLk9KkS82pWfl49adjiLh2HxYKQ/wyOhAdGzlo7XUdLU2w7NUAGBnIsON8Ir7bX3n3keUVqLAnJglvrz6Ndgv2YtDyCPzfpmisOHQdBy/fRWJqTrmCZXaeElfvZuDg5bv45+wd3E3PLXcdt0cnoP93RxD/IBvudUyx8a225foQUtl03is2KCgIbdq0wZIlSwAAKpUK7u7uePvtt/H+++8/c3ulUglbW1ssWbIEI0aMeGZ59oolItKd5PQcvP7LCZx91GN2WmgjLNp9CTn5Kizo74chFZxrVqkSGPrjUURel0JjgKct1r0RDINq1KJSHtl5SvT77jAuJqajtactlrzSCqPDjuNCQhpszIzwy+jAMk+tVlp/HIvD/22KhkwGhGkxPKpUApE3HuCvqDvYFp2A1OySO4hYKgzRwNEC3o4W8HayQENHC7jbmuFBZh4SUnNwJzUbd1KykZCSgzupOUhIzUZKluY+DeUyhDRxwpBAd3TwdijVz4VKJfDVnkv4du8VAEC7hnZYMrQVbM2Ny3/wZVRjhjvJy8uDmZkZNmzYgL59+6qXjxw5EikpKfjrr7+euY/09HQ4Ojpi/fr1eOmll55ZnsGOiEi3svOUmLL2NHaef9zjMri+Hf4YG6SVISPiH2ShxzcHoVIJbJ3UodiZIGqaG/cy0evbQ0jPLYCpkQGy85Wwt1Bg1etBpR4Opbze//Ms1hyPh7WpEf6e2B4eduWbVUQIgfN30rDlzB1sibqDxLTHHV0cLRXo1cIVL/o44l5GLi4nZeBycjouJ2fg5v0sKMvZOcFCYQgXaxMYyGW4mJiuXl7XxhSDWrtjUBs3uFibFrltek4+3lkbhT0XpKuIY9rXw8zuPjAs532T5VWW7GJYRXUq0r1796BUKuHkpDlXn5OTEy5eLN1o2TNmzICrqytCQkKKXJ+bm4vc3MdNr+np6UWWIyKiqmFqbIBlwwKwYMdF/PDvNSgM5Zjf309r44C51zHDrneeh0pI/7z1hZe9Ob4c1ALjfjuJ7Hwl6tqY4vfXg8o1u0dZze3TFBcS03EmPgVv/H4SG8e3halx6YeNuXEvE1vO3MFfUbdx9e7j+ystTQzRo5kL+vi7Iqi+XbEtaLkFSty8n6UR9q4kZeB2SjbsLIzham0KFxuTx19tTNXfPznEzMXENKyJjMem07dxOyUbX+25hK/DL6FTY0cMaeOOF30c1aHt2t0MjPvtJK4kZ8DYUI75/fwwIKD6NwjpNNhV1IIFC7BmzRrs378fJiYmRZaZP38+5s6dW8U1IyKiksjlMvxfjybo7OMIazMjrbeqFdcCU9N1beqM//VthsNX7uHDl3yrLLgqDKWOAr2+PYQLCWl4f+NZLB7s/1QYV6kEbj7IQsydNFxISENMQhpi7qRptMwpDOUIaeKE3v6u6NTYAQrDZwdEhaEBGjlZopGTJYDy39fm42yFOb2b4v3uPthxLhGrI+Nw7PoD7L2YjL0Xk+FoqcDAADd4O1lg1l/nkZ5TAGcrE3w/PKDSLnVrW429FLtw4UL873//w549e9C6detiy/23xe727dvw9fXlpVgiIqIyOnrtPob9dAxKlcDM7j4Iqm+HmDtpiElIxYWEdFxISENW3tNjFcplQHtvB/Rp4YquTZ1gWcqBmqvCtbsZWHs8HhtO3sL9TM2heAI8bbHs1VZwtCy68aiq1JhLscbGxggICEB4eLg62KlUKoSHh2PixInFbvf555/jk08+wc6dO0sMdQCgUCigUCjUz9PS0rRSdyIiotrmufp2+KBHE8z7Jwbztxd9y5TCUA4fZ0v4ulrB18UKvq5WaOxsBQtF9bxIWN/BAjN7NMG7XRsj/EISVh+Px6HLdzG4jQfm9PYtVYtidaLzszx16lSMHDkSrVu3RmBgIBYvXozMzEyMHj0aADBixAjUrVsX8+fPBwB89tlnmDVrFv744w94eXkhMTERAGBhYQELCwudHQcREVFtMLqdFy4mpmHdiVuwMzeWAtyjENfU1QpeduZV3rlAG4wN5eju54Lufi4oUKpq5DEA1SDYDR48GHfv3sWsWbOQmJgIf39/7NixQ92hIi4uDnL545O7bNky5OXlYeDAgRr7mT17NubMmVOVVSciIqp1ZDIZPhvQHB++5AtLhaHWOr1UJzU11AHVYBy7qsbhToiIiKgmKUt2qbmRlIiIiIg0MNgRERER6QkGOyIiIiI9wWBHREREpCcY7IiIiIj0BIMdERERkZ5gsCMiIiLSEwx2RERERHqCwY6IiIhITzDYEREREekJBjsiIiIiPcFgR0RERKQnGOyIiIiI9IShritQ1VQqFQAgISFBxzUhIiIierbCzFKYYUpS64JdUlISACAwMFDHNSEiIiIqvaSkJHh4eJRYRiaEEFVUn2qhoKAAp0+fhpOTE+TyyrsSnZ6eDl9fX8TExMDS0rLSXqc6qs3HDtTu46/Nxw7U7uOvzccO1O7jr83HDlTN8atUKiQlJaFly5YwNCy5Ta7WBbuqkpaWBmtra6SmpsLKykrX1alStfnYgdp9/LX52IHaffy1+diB2n38tfnYgep3/Ow8QURERKQnGOyIiIiI9ASDXSVRKBSYPXs2FAqFrqtS5WrzsQO1+/hr87EDtfv4a/OxA7X7+GvzsQPV7/h5jx0RERGRnmCLHREREZGeYLAjIiIi0hMMdkRERER6gsGulJYuXQovLy+YmJggKCgIkZGRJZZfv349fHx8YGJiAj8/P2zbtk1jvRACs2bNgouLC0xNTRESEoLLly9X5iFUSFmO/8cff0SHDh1ga2sLW1tbhISEPFV+1KhRkMlkGo9u3bpV9mGUS1mOPSws7KnjMjEx0Sijz+99p06dnjp+mUyGnj17qsvUlPf+33//Ra9eveDq6gqZTIbNmzc/c5v9+/ejVatWUCgUaNiwIcLCwp4qU9a/JbpQ1mPfuHEjunTpAgcHB1hZWSE4OBg7d+7UKDNnzpyn3ncfH59KPIryK+vx79+/v8if+8TERI1y+vjeF/X7LJPJ0LRpU3WZmvLez58/H23atIGlpSUcHR3Rt29fxMbGPnO76vb/nsGuFNauXYupU6di9uzZOHXqFFq0aIHQ0FAkJycXWf7IkSMYOnQoxowZg9OnT6Nv377o27cvzp07py7z+eef45tvvsHy5ctx7NgxmJubIzQ0FDk5OVV1WKVW1uPfv38/hg4din379iEiIgLu7u7o2rUrbt++rVGuW7duSEhIUD9Wr15dFYdTJmU9dgCwsrLSOK6bN29qrNfn937jxo0ax37u3DkYGBjg5Zdf1ihXE977zMxMtGjRAkuXLi1V+evXr6Nnz5544YUXEBUVhSlTpuD111/XCDjl+XnShbIe+7///osuXbpg27ZtOHnyJF544QX06tULp0+f1ijXtGlTjff90KFDlVH9Civr8ReKjY3VOD5HR0f1On1977/++muNY46Pj0edOnWe+p2vCe/9gQMHMGHCBBw9ehS7d+9Gfn4+unbtiszMzGK3qZb/7wU9U2BgoJgwYYL6uVKpFK6urmL+/PlFlh80aJDo2bOnxrKgoCDxxhtvCCGEUKlUwtnZWXzxxRfq9SkpKUKhUIjVq1dXwhFUTFmP/78KCgqEpaWl+OWXX9TLRo4cKfr06aPtqmpdWY995cqVwtrautj91bb3/quvvhKWlpYiIyNDvaymvPdPAiA2bdpUYpn33ntPNG3aVGPZ4MGDRWhoqPp5Rc+nLpTm2Ivi6+sr5s6dq34+e/Zs0aJFC+1VrIqU5vj37dsnAIiHDx8WW6a2vPebNm0SMplM3LhxQ72spr73ycnJAoA4cOBAsWWq4/97ttg9Q15eHk6ePImQkBD1MrlcjpCQEERERBS5TUREhEZ5AAgNDVWXv379OhITEzXKWFtbIygoqNh96kp5jv+/srKykJ+fjzp16mgs379/PxwdHdG4cWOMHz8e9+/f12rdK6q8x56RkQFPT0+4u7ujT58+OH/+vHpdbXvvf/75ZwwZMgTm5uYay6v7e18ez/q918b5rClUKhXS09Of+p2/fPkyXF1dUb9+fQwbNgxxcXE6qmHl8Pf3h4uLC7p06YLDhw+rl9em9/7nn39GSEgIPD09NZbXxPc+NTUVAJ76OX5Sdfx/z2D3DPfu3YNSqYSTk5PGcicnp6funyiUmJhYYvnCr2XZp66U5/j/a8aMGXB1ddX4we7WrRt+/fVXhIeH47PPPsOBAwfQvXt3KJVKrda/Ispz7I0bN8aKFSvw119/4ffff4dKpULbtm1x69YtALXrvY+MjMS5c+fw+uuvayyvCe99eRT3e5+Wlobs7Gyt/C7VFAsXLkRGRgYGDRqkXhYUFISwsDDs2LEDy5Ytw/Xr19GhQwekp6frsKba4eLiguXLl+PPP//En3/+CXd3d3Tq1AmnTp0CoJ2/ozXBnTt3sH379qd+52vie69SqTBlyhS0a9cOzZo1K7Zcdfx/b1gpeyV6ZMGCBVizZg3279+v0YlgyJAh6u/9/PzQvHlzNGjQAPv370fnzp11UVWtCA4ORnBwsPp527Zt0aRJE3z//ff4+OOPdVizqvfzzz/Dz88PgYGBGsv19b0nyR9//IG5c+fir7/+0rjHrHv37urvmzdvjqCgIHh6emLdunUYM2aMLqqqNY0bN0bjxo3Vz9u2bYurV6/iq6++wm+//abDmlWtX375BTY2Nujbt6/G8pr43k+YMAHnzp2rlvcCPgtb7J7B3t4eBgYGSEpK0lielJQEZ2fnIrdxdnYusXzh17LsU1fKc/yFFi5ciAULFmDXrl1o3rx5iWXr168Pe3t7XLlypcJ11paKHHshIyMjtGzZUn1cteW9z8zMxJo1a0r1R7s6vvflUdzvvZWVFUxNTbXy81TdrVmzBq+//jrWrVv31OWp/7KxsUGjRo1q/PtenMDAQPWx1Yb3XgiBFStWYPjw4TA2Ni6xbHV/7ydOnIh//vkH+/btg5ubW4llq+P/ewa7ZzA2NkZAQADCw8PVy1QqFcLDwzVaZp4UHBysUR4Adu/erS5fr149ODs7a5RJS0vDsWPHit2nrpTn+AGpF9DHH3+MHTt2oHXr1s98nVu3buH+/ftwcXHRSr21obzH/iSlUono6Gj1cdWG9x6Quv/n5ubi1VdffebrVMf3vjye9XuvjZ+n6mz16tUYPXo0Vq9erTG8TXEyMjJw9erVGv++FycqKkp9bPr+3gNSj9IrV66U6sNcdX3vhRCYOHEiNm3ahL1796JevXrP3KZa/r+vlC4ZembNmjVCoVCIsLAwERMTI8aNGydsbGxEYmKiEEKI4cOHi/fff19d/vDhw8LQ0FAsXLhQXLhwQcyePVsYGRmJ6OhodZkFCxYIGxsb8ddff4mzZ8+KPn36iHr16ons7OwqP75nKevxL1iwQBgbG4sNGzaIhIQE9SM9PV0IIUR6erqYNm2aiIiIENevXxd79uwRrVq1Et7e3iInJ0cnx1icsh773Llzxc6dO8XVq1fFyZMnxZAhQ4SJiYk4f/68uow+v/eF2rdvLwYPHvzU8pr03qenp4vTp0+L06dPCwBi0aJF4vTp0+LmzZtCCCHef/99MXz4cHX5a9euCTMzMzF9+nRx4cIFsXTpUmFgYCB27NihLvOs81ldlPXYV61aJQwNDcXSpUs1fudTUlLUZd59912xf/9+cf36dXH48GEREhIi7O3tRXJycpUf37OU9fi/+uorsXnzZnH58mURHR0tJk+eLORyudizZ4+6jL6+94VeffVVERQUVOQ+a8p7P378eGFtbS3279+v8XOclZWlLlMT/t8z2JXSt99+Kzw8PISxsbEIDAwUR48eVa/r2LGjGDlypEb5devWiUaNGgljY2PRtGlTsXXrVo31KpVKfPTRR8LJyUkoFArRuXNnERsbWxWHUi5lOX5PT08B4KnH7NmzhRBCZGVlia5duwoHBwdhZGQkPD09xdixY6vdH7hCZTn2KVOmqMs6OTmJHj16iFOnTmnsT5/feyGEuHjxogAgdu3a9dS+atJ7XziExX8fhcc7cuRI0bFjx6e28ff3F8bGxqJ+/fpi5cqVT+23pPNZXZT12Dt27FhieSGkoV9cXFyEsbGxqFu3rhg8eLC4cuVK1R5YKZX1+D/77DPRoEEDYWJiIurUqSM6deok9u7d+9R+9fG9F0IavsPU1FT88MMPRe6zprz3RR03AI3f45rw/1726GCIiIiIqIbjPXZEREREeoLBjoiIiEhPMNgRERER6QkGOyIiIiI9wWBHREREpCcY7IiIiIj0BIMdERERkZ5gsCMiIiLSEwx2RERVTCaTYfPmzbquBhHpIQY7IqpVRo0aBZlM9tSjW7duuq4aEVGFGeq6AkREVa1bt25YuXKlxjKFQqGj2hARaQ9b7Iio1lEoFHB2dtZ42NraApAuky5btgzdu3eHqakp6tevjw0bNmhsHx0djRdffBGmpqaws7PDuHHjkJGRoVFmxYoVaNq0KRQKBVxcXDBx4kSN9ffu3UO/fv1gZmYGb29vbNmyRb3u4cOHGDZsGBwcHGBqagpvb++ngigRUVEY7IiI/uOjjz7CgAEDcObMGQwbNgxDhgzBhQsXAACZmZkIDQ2Fra0tjh8/jvXr12PPnj0awW3ZsmWYMGECxo0bh+joaGzZsgUNGzbUeI25c+di0KBBOHv2LHr06IFhw4bhwYMH6tePiYnB9u3bceHCBSxbtgz29vZVdwKIqOYSRES1yMiRI4WBgYEwNzfXeHzyySdCCCEAiDfffFNjm6CgIDF+/HghhBA//PCDsLW1FRkZGer1W7duFXK5XCQmJgohhHB1dRUffPBBsXUAID788EP184yMDAFAbN++XQghRK9evcTo0aO1c8BEVKvwHjsiqnVeeOEFLFu2TGNZnTp11N8HBwdrrAsODkZUVBQA4MKFC2jRogXMzc3V69u1aweVSoXY2FjIZDLcuXMHnTt3LrEOzZs3V39vbm4OKysrJCcnAwDGjx+PAQMG4NSpU+jatSv69u2Ltm3blutYiah2YbAjolrH3Nz8qUuj2mJqalqqckZGRhrPZTIZVCoVAKB79+64efMmtm3bht27d6Nz586YMGECFi5cqPX6EpF+4T12RET/cfTo0aeeN2nSBADQpEkTnDlzBpmZmer1hw8fhlwuR+PGjWFpaQkvLy+Eh4dXqA4ODg4YOXIkfv/9dyxevBg//PBDhfZHRLUDW+yIqNbJzc1FYmKixjJDQ0N1B4X169ejdevWaN++PVatWoXIyEj8/PPPAIBhw4Zh9uzZGDlyJObMmYO7d+/i7bffxvDhw+Hk5AQAmDNnDt588004Ojqie/fuSE9Px+HDh/H222+Xqn6zZs1CQEAAmjZtitzcXPzzzz/qYElEVBIGOyKqdXbs2AEXFxeNZY0bN8bFixcBSD1W16xZg7feegsuLi5YvXo1fH19AQBmZmbYuXMnJk+ejDZt2sDMzAwDBgzAokWL1PsaOXIkcnJy8NVXX2HatGmwt7fHwIEDS10/Y2NjzJw5Ezdu3ICpqSk6dOiANWvWaOHIiUjfyYQQQteVICKqLmQyGTZt2oS+ffvquipERGXGe+yIiIiI9ASDHREREZGe4D12RERP4N0pRFSTscWOiIiISE8w2BERERHpCQY7IiIiIj3BYEdERESkJxjsiIiIiPQEgx0RERGRnmCwIyIiItITDHZEREREeoLBjoiIiEhP/D9KvP9Wywko6wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.plots import plot_losses\n",
    "epochs_tensor = torch.linspace(0, 2, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a bull in a china shop.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is a cirrus.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "from inference.generate import generate\n",
    "for entry in test_data[:3]:      #1\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(               #2\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
